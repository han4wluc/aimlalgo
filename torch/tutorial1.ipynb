{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "as\t\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"as\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {}\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  2 : 30\n",
       "}\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2] = 30\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i=2,#b do\n",
    "--     print('hello')\n",
    "    print(b[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.3959  0.6097  0.2272  0.7579\n",
       " 1.6890  0.7654  0.3566  1.0577\n",
       " 1.2062  0.6639  0.2791  0.9630\n",
       " 0.5965  0.4077  0.0874  0.5354\n",
       " 1.1271  0.6314  0.2095  0.8545\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(5,3)\n",
    "b = torch.rand(3,4)\n",
    "c = a*b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.3959  0.6097  0.2272  0.7579\n",
       " 1.6890  0.7654  0.3566  1.0577\n",
       " 1.2062  0.6639  0.2791  0.9630\n",
       " 0.5965  0.4077  0.0874  0.5354\n",
       " 1.1271  0.6314  0.2095  0.8545\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet5\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> output]\n",
       "  (1): nn.SpatialConvolution(1 -> 6, 5x5)\n",
       "  (2): nn.ReLU\n",
       "  (3): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (4): nn.SpatialConvolution(6 -> 16, 5x5)\n",
       "  (5): nn.ReLU\n",
       "  (6): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (7): nn.View(400)\n",
       "  (8): nn.Linear(400 -> 120)\n",
       "  (9): nn.ReLU\n",
       "  (10): nn.Linear(120 -> 84)\n",
       "  (11): nn.ReLU\n",
       "  (12): nn.Linear(84 -> 10)\n",
       "  (13): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net = nn.Sequential()\n",
    "\n",
    "-- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.SpatialConvolution(1, 6, 5, 5))\n",
    "-- non-linearity\n",
    "net:add(nn.ReLU())\n",
    "-- A max-pooling operation that looks at 2x2 windows and finds the max\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))\n",
    "net:add(nn.Linear(16*5*5, 120))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Linear(84, 10))\n",
    "net:add(nn.LogSoftMax())\n",
    "\n",
    "print('Lenet5\\n' .. net:__tostring())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.2593\n",
       "-2.3320\n",
       "-2.3196\n",
       "-2.2942\n",
       "-2.3093\n",
       "-2.3310\n",
       "-2.2065\n",
       "-2.3042\n",
       "-2.3532\n",
       "-2.3249\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand(1,32,32)\n",
    "output = net:forward(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net:zeroGradParameters()\n",
    "gradInput = net:backward(input, torch.rand(10))\n",
    "-- print(#gradInput)\n",
    "-- print(gradInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3195872666718\t1\t\n",
       "-1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.ClassNLLCriterion()\n",
    "print(criterion:forward(output, 3))\n",
    "gradients = criterion:backward(output, 1)\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = nn.SpatialConvolution(1,3,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       " -0.2240 -0.3279\n",
       " -0.4103  0.1833\n",
       "\n",
       "(2,1,.,.) = \n",
       "  0.4879 -0.1554\n",
       " -0.3297 -0.3170\n",
       "\n",
       "(3,1,.,.) = \n",
       "  0.1105 -0.3612\n",
       " -0.2328  0.1298\n",
       "[torch.DoubleTensor of size 3x1x2x2]\n",
       "\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.1082\n",
       " 0.0032\n",
       "-0.4333\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- require 'image'\n",
    "-- require 'audio'\n",
    "-- require 'paths'\n",
    "-- if (not paths.filep(\"cifar10torchsmall.zip\")) then\n",
    "--     os.execute('wget -c https://s3.amazonaws.com/torch7/data/cifar10torchsmall.zip')\n",
    "--     os.execute('unzip cifar10torchsmall.zip')\n",
    "-- end\n",
    "\n",
    "-- trainset = torch.load('cifar10-train.t7')\n",
    "-- testset = torch.load('cifar10-text.t7')\n",
    "-- classes = {'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}\n",
    "\n",
    "-- print(trainset)\n",
    "\n",
    "require 'paths'\n",
    "if (not paths.filep(\"cifar10torchsmall.zip\")) then\n",
    "    os.execute('wget -c https://s3.amazonaws.com/torch7/data/cifar10torchsmall.zip')\n",
    "    os.execute('unzip cifar10torchsmall.zip')\n",
    "end\n",
    "trainset = torch.load('cifar10-train.t7')\n",
    "testset = torch.load('cifar10-test.t7')\n",
    "classes = {'airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : ByteTensor - size: 10000x3x32x32\n",
       "  label : ByteTensor - size: 10000\n",
       "}\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10000\n",
       "     3\n",
       "    32\n",
       "    32\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "automobile\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itorch.image(trainset.data[100])\n",
    "print(classes[trainset.label[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- ignore setmetatable for now, it is a feature beyond the scope of this tutorial. It sets the index operator.\n",
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "trainset.data = trainset.data:double()\n",
    "\n",
    "function trainset:size()\n",
    "    return self.data:size(1)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(trainset:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(trainset[33])\n",
    "itorch.image(trainset[33][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- this picks {all images, 1st channel, all vertical pixels, all horizontal pixels}\n",
    "redChannel = trainset.data[{ {151,300}, {1}, {}, {} }]\n",
    "\n",
    "print(#redChannel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"mean = {} -- store the mean, to normalize the...\"]:4: attempt to call method 'mean' (a nil value)\nstack traceback:\n\t[string \"mean = {} -- store the mean, to normalize the...\"]:4: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/vagrant/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"mean = {} -- store the mean, to normalize the...\"]:4: attempt to call method 'mean' (a nil value)\nstack traceback:\n\t[string \"mean = {} -- store the mean, to normalize the...\"]:4: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/vagrant/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670"
     ]
    }
   ],
   "source": [
    "mean = {} -- store the mean, to normalize the test set in the future\n",
    "stdv = {} -- store the standard-deviation for the future\n",
    "for i=1,3 do -- over each image channel\n",
    "    mean[i] = trainset.data[{ {}, {i}, {}, {} }]:mean() -- mean esitmation\n",
    "    print('Channel ' .. i .. ', Mean: ' .. mean[i])\n",
    "    trainset.data[{ {}, {i}, {}, {} }]:add(-mean[i]) -- mean subtraction\n",
    "    \n",
    "    stdv[i] = trainset.data[{ {}, {i}, {}, {} }]:std() -- std estimation\n",
    "    print('Channel ' .. i .. ', Standard Deviation: ' .. stdv[i])\n",
    "    trainset.data[{ {}, {i}, {}, {} }]:div(stdv[i]) -- std scaling\n",
    "end\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "\n",
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(3, 6, 5, 5)) -- 3 input image channels, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems\n",
    "\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5 -- just do 5 epochs of training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 2.2214433898642\t\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.9234136283678\t\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.7086791338919\t\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.5858928592758\t\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.4785566475306\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 1.4785566475306\t\n",
       "\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer:train(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "horse\t\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "horse\t\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])\n",
    "\n",
    "testset.data = testset.data:double()   -- convert from Byte tensor to Double tensor\n",
    "for i=1,3 do -- over each image channel\n",
    "    testset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction    \n",
    "    testset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59066009532189\t1.0665356205025\t\n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- for fun, print the mean and standard-deviation of example-100\n",
    "horse = testset.data[100]\n",
    "print(horse:mean(), horse:std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "horse\t\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])\n",
    "predicted = net:forward(testset.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0225\n",
       " 0.0154\n",
       " 0.0549\n",
       " 0.2022\n",
       " 0.0769\n",
       " 0.1933\n",
       " 0.0231\n",
       " 0.3050\n",
       " 0.0096\n",
       " 0.0970\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predicted:exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airplane\t0.022525643152023\t\n",
       "automobile\t0.01543048360784\t\n",
       "bird\t0.0548588700917\t\n",
       "cat\t0.20222203258894\t\n",
       "deer\t0.076925268540162\t\n",
       "dog\t0.19326944743958\t\n",
       "frog\t0.023115088618948\t\n",
       "horse\t0.30500353026259\t\n",
       "ship\t0.0096236619962843\t\n",
       "truck\t0.09702597370193\t\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i=1,predicted:size(1) do\n",
    "    print(classes[i], predicted[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4607\t46.07 % \t\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end\n",
    "\n",
    "print(correct, 100*correct/10000 .. ' % ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_performance = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        class_performance[groundtruth] = class_performance[groundtruth] + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airplane\t31.9 %\t\n",
       "automobile\t65.2 %\t\n",
       "bird\t13 %\t\n",
       "cat\t41.9 %\t\n",
       "deer\t24.6 %\t\n",
       "dog\t46.4 %\t\n",
       "frog\t67.7 %\t\n",
       "horse\t54.5 %\t\n",
       "ship\t72.8 %\t\n",
       "truck\t42.7 %\t\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i=1,#classes do\n",
    "    print(classes[i], 100*class_performance[i]/1000 .. ' %')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 6\n",
       " 7\n",
       " 7\n",
       "[torch.LongStorage of size 4]\n",
       "\n",
       " 294\n",
       "   1\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'nn'\n",
    "torch.manualSeed(1234)\n",
    "input = torch.rand(1,3,8,8)\n",
    "\n",
    "m = nn.SpatialConvolution(3,6,2,2)\n",
    "-- print(m.weight:size())\n",
    "o1 = m:forward(input)\n",
    "-- print(output)\n",
    "\n",
    "-- output = torch.rand(7)\n",
    "-- c:forward(output, 2)\n",
    "\n",
    "-- net:add(nn.View(16*5*5))\n",
    "-- print(o1:size())\n",
    "-- m2 = nn.View(3*7*7)\n",
    "print(o1:size())\n",
    "-- m2 = nn.View(-1):setNumInputDims(3)\n",
    "m2 = nn.View(1)\n",
    "o2 = m2:forward(o1)\n",
    "print(o2:size())\n",
    "\n",
    "-- m3 = nn.Linear(3*7*7, 5)\n",
    "-- o3 = m3:forward(o2)\n",
    "-- print(o3)\n",
    "\n",
    "-- m4 = nn.SoftMax()\n",
    "-- o4 = m4:forward(o3)\n",
    "-- print(o4)\n",
    "\n",
    "\n",
    "-- c = nn.ClassNLLCriterion()\n",
    "-- loss = c:forward(o4, 1)\n",
    "-- print(loss)\n",
    "\n",
    "-- gradInput = c:updateGradInput(o4, 1)\n",
    "-- print(gradInput)\n",
    "-- c.gradInput\n",
    "\n",
    "-- module:updateGradInput(input, criterion:updateGradInput(module.output, target))\n",
    "\n",
    "\n",
    "\n",
    "-- print(m.output:size())\n",
    "-- output = m:updateOutput(input):size()\n",
    "-- print(m.output:size())\n",
    "-- m.weight\n",
    "-- criterion = nn.ClassNLLCriterion()\n",
    "\n",
    "\n",
    "-- print(output)\n",
    "-- print(m.weight)\n",
    "\n",
    "-- criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "./nn/ClassNLLCriterion.lua:44: attempt to index field 'THNN' (a nil value)\nstack traceback:\n\t./nn/ClassNLLCriterion.lua:44: in function 'forward'\n\t[string \"torch.manualSeed(1234)...\"]:14: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/vagrant/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "./nn/ClassNLLCriterion.lua:44: attempt to index field 'THNN' (a nil value)\nstack traceback:\n\t./nn/ClassNLLCriterion.lua:44: in function 'forward'\n\t[string \"torch.manualSeed(1234)...\"]:14: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/vagrant/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...e/vagrant/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/vagrant/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670"
     ]
    }
   ],
   "source": [
    "torch.manualSeed(1234)\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "-- function softmax(X)\n",
    "--     local num = X:exp()\n",
    "--     local den = X:exp():sum()\n",
    "--     return num:div(den)\n",
    "-- end\n",
    "\n",
    "\n",
    "-- probs = softmax(output)\n",
    "-- print(softmax(output))\n",
    "\n",
    "for i = 1,40 do\n",
    "    loss = criterion:forward(output,2)\n",
    "--     print('loss', loss)\n",
    "    grad = criterion:backward(output, 2)\n",
    "    output = output - (grad * 0.05)\n",
    "end\n",
    "\n",
    "-- print(softmax(output))\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- for key,value in pairs(getmetatable(m)) do\n",
    "--     print(key, value)\n",
    "-- end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.DoubleTensor\t\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.type(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- assert(input.THNN, torch.type(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- input.THNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- for key,value in pairs(getmetatable(o)) do\n",
    "--     print(key, value)\n",
    "-- end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "-- while true do\n",
    "--   local currentError = 0\n",
    "--   for t = 1,dataset:size() do\n",
    "--      local example = dataset[shuffledIndices[t]]\n",
    "--      local input = example[1]\n",
    "--      local target = example[2]\n",
    "\n",
    "--      currentError = currentError + criterion:forward(module:forward(input), target)\n",
    "\n",
    "--      module:updateGradInput(input, criterion:updateGradInput(module.output, target))\n",
    "--      module:accUpdateGradParameters(input, criterion.gradInput, currentLearningRate)\n",
    "\n",
    "--      if self.hookExample then\n",
    "--         self.hookExample(self, example)\n",
    "--      end\n",
    "--   end\n",
    "--   currentError = currentError / dataset:size()\n",
    "-- end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet5\n",
       "\tnn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> output]\n",
       "  (1): nn.SpatialConvolution(1 -> 6, 5x5)\n",
       "  (2): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (3): nn.Tanh\n",
       "  (4): nn.SpatialConvolution(6 -> 16, 5x5)\n",
       "  (5): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (6): nn.Tanh\n",
       "  (7): nn.View(-1)\n",
       "  (8): nn.Linear(400 -> 120)\n",
       "  (9): nn.Tanh\n",
       "  (10): nn.Linear(120 -> 84)\n",
       "  (11): nn.Tanh\n",
       "  (12): nn.Linear(84 -> 10)\n",
       "}\t\n"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "\n",
    "-- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.SpatialConvolution(1, 6, 5, 5))\n",
    "\n",
    "-- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "\n",
    "-- non-linearity\n",
    "net:add(nn.Tanh())\n",
    "\n",
    "-- additional layers\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.Tanh())\n",
    "\n",
    "-- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.View(-1):setNumInputDims(3))\n",
    "\n",
    "-- fully connected layers (matrix multiplication between input and weights)\n",
    "net:add(nn.Linear(16*5*5, 120))\n",
    "net:add(nn.Tanh())\n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.Tanh())\n",
    "\n",
    "-- 10 is the number of outputs of the network (10 classes)\n",
    "net:add(nn.Linear(84, 10))\n",
    "print('Lenet5\\n', tostring(net));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- require 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = require 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
