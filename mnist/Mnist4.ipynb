{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import array\n",
    "import time\n",
    "import pandas as pd\n",
    "# import scipy.sparse\n",
    "import scipy.optimize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 785)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./mnist_train.csv')[:4000]\n",
    "# test = pd.read_csv('./mnist_test.csv', header=None)\n",
    "\n",
    "matrix = df.as_matrix()\n",
    "print matrix.shape\n",
    "m = matrix.shape[0]\n",
    "y = matrix[:,0:1]\n",
    "X = matrix[:,1:]\n",
    "\n",
    "# matrix_test = test.as_matrix()\n",
    "# X_test = matrix_test[:,1:]\n",
    "# m_test = X_test.shape[0]\n",
    "# y_test = matrix_test[:,0:1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "\n",
    "$\n",
    "h_\\theta(x^{(i)}) = \n",
    "\\begin{bmatrix}\n",
    "    p(y^{(i)} = 1 \\:|\\: x{(i)};\\theta) \\\\\n",
    "    p(y^{(i)} = 2 \\:|\\: x{(i)};\\theta) \\\\\n",
    "    ... \\\\\n",
    "    p(y^{(i)} = k \\:|\\: x{(i)};\\theta) \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\frac{1}{\\sum_{j=1}^{k}e^{\\theta^{T}_jx^{(i)}}}\n",
    "\\begin{bmatrix}\n",
    "    e^{\\theta^{T}_1x^{(i)}} \\\\\n",
    "    e^{\\theta^{T}_2x^{(i)}} \\\\\n",
    "    ...                     \\\\\n",
    "    e^{\\theta^{T}_kx^{(i)}} \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "$\n",
    "J(\\theta) = -\\frac{1}{m}[\\sum_{i=1}^{m}\\sum_{j=1}^{k}1\\{y^{(i)}=j\\}\\:log\\frac{e^{\\theta_j^Tx^{(i)}}}{\\sum_{l=1}^{k}e^{\\theta_l^Tx^{(i)}}}]\n",
    "$\n",
    "\n",
    "### Gradient\n",
    "\n",
    "\n",
    "$\n",
    "\\Delta_{\\theta_j}J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}[x^{(i)}(1\\{y^{(i)}=j\\} - p(y^{(i)} = j\\:|\\:x^{(i)};\\theta))] + \\lambda\\theta_j\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n",
      "(1000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print theta.shape\n",
    "print X.shape\n",
    "\n",
    "X.dot(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n"
     ]
    }
   ],
   "source": [
    "print theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(1, 2)\n",
      "[[ 2  6]\n",
      " [10 30]]\n"
     ]
    }
   ],
   "source": [
    "aa = np.array([[1],[5]])\n",
    "bb = np.array([[2,6]])\n",
    "\n",
    "print aa.shape\n",
    "print bb.shape\n",
    "\n",
    "print aa .dot( bb )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# theta = 0.0005 * np.random.rand(X.shape[1],len(np.unique(y)))\n",
    "\n",
    "n_of_features = X.shape[1]\n",
    "k = len(np.unique(y))\n",
    "rand = np.random.RandomState(10)\n",
    "theta = 0.0005 * rand.rand(n_of_features, k)\n",
    "\n",
    "def hypothesis(X, theta):\n",
    "    \n",
    "    # Compute hypothesis\n",
    "#     print 'X.shape', X.shape\n",
    "#     print 'theta.shape', theta.shape\n",
    "#     print 'X', X.T\n",
    "#     print 'X[0]', X[0]\n",
    "#     print 'X.shape', X.T.shape\n",
    "#     print 'theta', theta.T\n",
    "#     print 'theta.shape', theta.T.shape\n",
    "    \n",
    "#     print 'X.sum()', X.sum()\n",
    "#     print 'theta.sum()', theta.sum()\n",
    "\n",
    "#     print 'theta_x_1', np.dot(X, theta) \n",
    "    theta_x = np.dot(theta.T, X.T)\n",
    "#     print 'theta_x', theta_x\n",
    "#     print 'theta_x.shape', theta_x.shape\n",
    "#     print 'theta_x.sum()', theta_x.sum()\n",
    "    \n",
    "    h = np.exp(np.dot(X, theta))\n",
    "#     print 'h', h\n",
    "    \n",
    "    # Normalize the hypothesis so each row sums to 1\n",
    "    summation = h.sum(axis=0)\n",
    "#     print 'summation', summation\n",
    "    h = h / summation\n",
    "\n",
    "    return h\n",
    "\n",
    "def to_one_hot(y):\n",
    "    K = len(np.unique(y.ravel()))\n",
    "    one_hot = np.zeros(shape=(m, K))\n",
    "    for i, row in enumerate(one_hot):\n",
    "        if i < 10:\n",
    "            idx = y[i][0]\n",
    "            row[idx] = 1\n",
    "    return one_hot\n",
    "\n",
    "def compute_weight_decay(theta, lam):\n",
    "    theta_squared = theta ** 2\n",
    "    weight_decay = 0.5 * lam * theta_squared.sum()\n",
    "    return weight_decay\n",
    "\n",
    "def softmax_cost(X, y, theta, lam=0.0001):\n",
    "    m = X.shape[0]\n",
    "    y_one_hot = to_one_hot(y)\n",
    "    h = hypothesis(X, theta)\n",
    "    traditional_cost = -(1.0)/m * (np.multiply(y_one_hot, np.log(h))).sum()\n",
    "\n",
    "    weight_decay = compute_weight_decay(theta, lam)\n",
    "\n",
    "    cost = traditional_cost + weight_decay\n",
    "    gradient = compute_gradient(X, y, theta)\n",
    "    return cost, gradient\n",
    "\n",
    "def compute_gradient(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    h = hypothesis(X, theta)\n",
    "    y_one_hot = to_one_hot(y)\n",
    "    errors = y_one_hot - h\n",
    "    weights_decay = (0.5 * theta) #.sum()\n",
    "    summation = np.dot(X.T, errors) #.sum() \n",
    "    return (-(summation / m)) + weights_decay\n",
    "    \n",
    "    \n",
    "def gradient_descent(X, y, theta, num_of_iterations, alpha, lam):\n",
    "    theta = 0.0005 * np.random.rand(X.shape[1],len(np.unique(y)))\n",
    "    \n",
    "    costs = []\n",
    "    for i in range(num_of_iterations):\n",
    "        if i % 100 == 0:\n",
    "            print 'doing', i\n",
    "        cost, gradient = softmax_cost(X, y, theta, lam)\n",
    "        costs.append(cost)\n",
    "        theta = theta - (alpha * gradient)\n",
    "    return theta, costs\n",
    "\n",
    "def feature_normalize(X):\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X, ddof=1)\n",
    "    return ( X - mean ) / std\n",
    "\n",
    "def normalize_0_1(X):\n",
    "    _min = np.min(X)\n",
    "    _max = np.max(X)\n",
    "    return (X-_min) / float(_max - _min)\n",
    "#     mean = np.mean(X)\n",
    "#     std = np.std(X, ddof=1)\n",
    "#     return ( X - mean ) / std\n",
    "\n",
    "def gradient_checking(selectors, theta, epsilon):\n",
    "    n, k = theta.shape\n",
    "#     theta = theta.flatten()\n",
    "    grad_approx = np.zeros(len(selectors));\n",
    "#     for i, _ in enumerate(theta):\n",
    "    for i, sel in enumerate(selectors):\n",
    "#         print i\n",
    "        theta_plus = theta.copy()\n",
    "        theta_minus = theta.copy()\n",
    "        \n",
    "        theta_plus[sel]  += epsilon\n",
    "        theta_minus[sel] -= epsilon\n",
    "        \n",
    "        cost_plus, _ = softmax_cost(X, y, theta_plus, 0.001)\n",
    "#         print 'cost_plus ', cost_plus\n",
    "#         print _\n",
    "#         print _.shape\n",
    "        cost_minus, _ = softmax_cost(X, y, theta_minus, 0.001)\n",
    "#         print 'cost_minus', cost_minus\n",
    "        grad_approx[i] = (cost_plus - cost_minus) / (2 * epsilon)\n",
    "    return grad_approx\n",
    "#     return theta.reshape(n, k)\n",
    "\n",
    "\n",
    "def reshape_gradient(gradient, sel):\n",
    "    gradient_reshaped = np.zeros(len(sel))\n",
    "    for i, s in enumerate(sel):\n",
    "        gradient_reshaped[i] = gradient[s]\n",
    "#     print gradient_reshaped.shape\n",
    "    return gradient_reshaped\n",
    "\n",
    "def generate_selector(theta):\n",
    "#     sel = np.full(theta.shape, False, dtype=bool)\n",
    "    sel = []\n",
    "    i = 0\n",
    "    for a, __ in np.ndenumerate(theta):\n",
    "        if i % 401 == 0:\n",
    "#             print i\n",
    "#             sel[a] = True\n",
    "            sel.append(a)\n",
    "        i += 1\n",
    "    return sel\n",
    "\n",
    "\n",
    "def calc_gradient_diff(gradient_check, gradient, sel):\n",
    "#     print gradient.shape\n",
    "    nn = gradient.shape[0] * gradient.shape[1]\n",
    "    multiplier = float(nn) / len(sel)\n",
    "    gradient_check_actual = reshape_gradient(gradient, sel)\n",
    "    return (gradient_check - gradient_check_actual).sum() * multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48164336036319993"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sel = generate_selector(theta)\n",
    "\n",
    "gradient_check = gradient_checking(sel, theta, 0.0001)\n",
    "cost, gradient = softmax_cost(X, y, theta, 0.0001)\n",
    "\n",
    "calc_gradient_diff(gradient_check, gradient, sel)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154,)\n",
      "(154,)\n",
      "-0.0268010144068\n"
     ]
    }
   ],
   "source": [
    "print gradient_check.shape\n",
    "# print gradient[sel].shape\n",
    "# print gradient[sel]\n",
    "gradients = np.zeros(len(sel))\n",
    "for i, s in enumerate(sel):\n",
    "    gradients[i] = gradient[s]\n",
    "print gradients.shape\n",
    "\n",
    "print (gradient_check - gradients).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-1a28ae540196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# new_theta, costs = gradient_descent(X_normalized, y, theta, 50, 1, 0.0001)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnew_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "# \n",
    "rand = np.random.RandomState(13)\n",
    "# theta = 0.0005 * rand.rand(n_of_features, k)\n",
    "theta = 1 * rand.rand(n_of_features, k)\n",
    "\n",
    "\n",
    "X_normalized = feature_normalize(X)\n",
    "# new_theta, costs = gradient_descent(X_normalized, y, theta, 50, 1, 0.0001)\n",
    "new_theta, costs = gradient_descent(s, y, theta, 100, 0.15, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdedc9dad10>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEACAYAAABCl1qQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMysqP8PJdIZmSr1MJMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdedca58f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(costs)\n",
    "# print costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21225\n"
     ]
    }
   ],
   "source": [
    "hyp = hypothesis(X, new_theta)\n",
    "predicted_table = np.argmax(hyp, axis=1)\n",
    "predicted_table = np.reshape(predicted_table, (m,1))\n",
    "correct = (predicted_table == y).sum()\n",
    "print float(correct) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# opt_solution = scipy.optimize.minimize(\n",
    "#     softmax_cost,\n",
    "#     theta,\n",
    "#     args = (\n",
    "#         X,\n",
    "#         y,\n",
    "#     ),\n",
    "#     method = 'L-BFGS-B',\n",
    "#     jac = True,\n",
    "#     options = {\n",
    "#         'maxiter': 10\n",
    "#     }\n",
    "# )\n",
    "# # opt_theta = opt_solution.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "alpha = 0.0001\n",
    "lam = 0.0001\n",
    "\n",
    "# theta = 0.0005 * rand.rand(n_of_features, k)\n",
    "# print 'theta', theta\n",
    "# X_normalized = normalize_0_1(X)\n",
    "# print 'X_normalized', X_normalized[0]\n",
    "# print 'hypothesis', hypothesis(X_normalized, theta)\n",
    "# print 'decay', compute_weight_decay(theta, lam)\n",
    "# cost, gradient = softmax_cost(X_normalized, y, theta, lam)\n",
    "# print 'cost', cost\n",
    "# print 'gradient', gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print X.T * errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  51 159 253 159  50   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84 252\n",
      " 253 122   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
      "  47  79 255 168   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0\n",
      "   0   0   0   0 253 252 165   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  57 252 252  63   0   0   0\n",
      "   0   0   0   0   0   0 253 252 195   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255 253\n",
      " 196   0   0   0   0   0   0   0   0   0   0   0  76 246 252 112   0   0\n",
      "   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0   0   0\n",
      "   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7 135\n",
      " 253 186  12   0   0   0   0   0   0   0   0   0   0   0  85 252 223   0\n",
      "   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
      " 252 173   0   0   0   0   0   0   0   0   0   0   0   0   0   0  86 253\n",
      " 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253\n",
      " 223 167  56   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  28 199 252 252 253 252 252 233\n",
      " 145   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "[[0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5 6 0\n",
      "  7 6 1 8 7 9 3 9 8 5 9 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 1 7 1 6 3\n",
      "  0 2 1 1 7 9 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1 5 7 1 7 1 1 6 3 0 2 9 3\n",
      "  1 1 0 4 9 2 0 0 2 0 2 7 1 8 6 4 1 6 3 4 5 9 1 3 3 8 5 4 7 7 4 2 8 5 8 6 7\n",
      "  3 4 6 1 9 9 6 0 3 7 2 8 2 9 4 4 6 4 9 7 0 9 2 9 5 1 5 9 1 2 3 2 3 5 9 1 7\n",
      "  6 2 8 2 2 5 0 7 4 9 7 8 3 2 1 1 8 3 6 1 0 3 1 0 0 1 7 2 7 3 0 4 6 5 2 6 4\n",
      "  7 1 8 9 9 3 0 7 1 0 2 0 3 5 4 6 5 8 6 3 7 5 8 0 9 1 0 3 1 2 2 3 3 6 4 7 5\n",
      "  0 6 2 7 9 8 5 9 2 1 1 4 4 5 6 4 1 2 5 3 9 3 9 0 5 9 6 5 7 4 1 3 4 0 4 8 0\n",
      "  4 3 6 8 7 6 0 9 7 5 7 2 1 1 6 8 9 4 1 5 2 2 9 0 3 9 6 7 2 0 3 5 4 3 6 5 8\n",
      "  9 5 4 7 4 2 7 3 4 8 9 1 9 2 8 7 9 1 8 7 4 1 3 1 1 0 2 3 9 4 9 2 1 6 8 4 7\n",
      "  7 4 4 9 2 5 7 2 4 4 2 1 9 7 2 8 7 6 9 2 2 3 8 1 6 5 1 1 0 2 6 4 5 8 3 1 5\n",
      "  1 9 2 7 4 4 4 8 1 5 8 9 5 6 7 9 9 3 7 0 9 0 6 6 2 3 9 0 7 5 4 8 0 9 4 1 2\n",
      "  8 7 1 2 6 1 0 3 0 1 1 8 2 0 3 9 4 0 5 0 6 1 7 7 8 1 9 2 0 5 1 2 2 7 3 5 4\n",
      "  9 7 1 8 3 9 6 0 3 1 1 2 6 3 5 7 6 8 3 9 5 8 5 7 6 1 1 3 1 7 5 5 5 2 5 8 7\n",
      "  0 9 7 7 5 0 9 0 0 8 9 2 4 8 1 6 1 6 5 1 8 3 4 0 5 5 8 3 6 2 3 9 2 1 1 5 2\n",
      "  1 3 2 8 7 3 7 2 4 6 9 7 2 4 2 8 1 1 3 8 4 0 6 5 9 3 0 9 2 4 7 1 2 9 4 2 6\n",
      "  1 8 9 0 6 6 7 9 9 8 0 1 4 4 6 7 1 5 7 0 3 5 8 4 7 1 2 5 9 5 6 7 5 9 8 8 3\n",
      "  6 9 7 0 7 5 7 1 1 0 7 9 2 3 7 3 2 4 1 6 2 7 5 5 7 4 0 2 6 3 6 4 0 4 2 6 0\n",
      "  0 0 0 3 1 6 2 2 3 1 4 1 5 4 6 4 7 2 8 7 9 2 0 5 1 4 2 8 3 2 4 1 5 4 6 0 7\n",
      "  9 8 4 9 8 0 1 1 0 2 2 3 2 4 4 5 8 6 5 7 7 8 8 9 7 4 7 3 2 0 8 6 8 6 1 6 8\n",
      "  9 4 0 9 0 4 1 5 4 7 5 3 7 4 9 8 5 8 6 3 8 6 9 9 1 8 3 5 8 6 5 9 7 2 5 0 8\n",
      "  5 1 1 0 9 1 8 6 7 0 9 3 0 8 8 9 6 7 8 4 7 5 9 2 6 7 4 5 9 2 3 1 6 3 9 2 2\n",
      "  5 6 8 0 7 7 1 9 8 7 0 9 9 4 6 2 8 5 1 4 1 5 5 1 7 3 6 4 3 2 5 6 4 4 0 4 4\n",
      "  6 7 2 4 3 3 8 0 0 3 2 2 9 8 2 3 7 0 1 1 0 2 3 3 8 4 3 5 7 6 4 7 7 8 5 9 7\n",
      "  0 3 1 6 2 4 3 4 4 7 5 9 6 9 0 7 1 4 2 7 3 6 7 5 8 4 5 5 2 7 1 1 5 6 8 5 8\n",
      "  4 0 7 9 9 2 9 7 7 8 7 4 2 6 9 1 7 0 6 4 2 5 7 0 7 1 0 3 7 6 5 0 6 1 5 1 7\n",
      "  8 5 0 3 4 7 7 5 7 8 6 9 3 8 6 1 0 9 7 1 3 0 5 6 4 4 2 4 4 3 1 7 7 6 0 3 6\n",
      "  0]]\n",
      "[[  3.85660322e-04   1.03759747e-05   3.16824117e-04 ...,   3.80265356e-04\n",
      "    8.45554183e-05   4.41699071e-05]\n",
      " [  3.42679909e-04   4.76696673e-04   1.97413316e-06 ...,   1.45938034e-04\n",
      "    4.58887061e-04   3.57287892e-04]\n",
      " [  2.71272184e-04   7.10850238e-05   1.86670380e-04 ...,   2.56569121e-04\n",
      "    3.25198591e-04   3.00519477e-04]\n",
      " ..., \n",
      " [  3.48713905e-04   1.56844888e-04   1.02725541e-04 ...,   9.49769320e-05\n",
      "    3.15085083e-04   4.70179917e-04]\n",
      " [  4.94031613e-05   2.77312323e-04   1.47121887e-04 ...,   1.56144800e-04\n",
      "    4.21690755e-04   4.74061754e-04]\n",
      " [  4.46830018e-04   1.25052283e-04   4.76457935e-05 ...,   4.98374494e-04\n",
      "    1.15055453e-04   4.47175715e-04]]\n"
     ]
    }
   ],
   "source": [
    "print X[0]\n",
    "print y.T\n",
    "print theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X\n",
    "# print y\n",
    "print theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.02750991  7.65829303  8.22492154 ...,  7.57622251  7.71207028\n",
      "   7.86756045]\n",
      " [ 4.59951021  5.17384386  4.93871541 ...,  4.73542002  4.88209247\n",
      "   5.10557152]\n",
      " [ 3.966941    4.10703155  4.34924595 ...,  3.72894257  4.59960936\n",
      "   4.79950616]\n",
      " ..., \n",
      " [ 4.94369233  5.86620593  5.6433769  ...,  4.93204326  5.88177398\n",
      "   5.57196998]\n",
      " [ 6.09087626  6.60208114  7.0593024  ...,  5.8579878   6.36091286\n",
      "   6.73509632]\n",
      " [ 5.75268281  6.29468164  6.62473448 ...,  5.72080664  5.6044771\n",
      "   6.28099406]]\n"
     ]
    }
   ],
   "source": [
    "print np.dot(X, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
