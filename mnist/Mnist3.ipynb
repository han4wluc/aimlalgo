{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import array\n",
    "import time\n",
    "import scipy.sparse\n",
    "import scipy.optimize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" The Softmax Regression class \"\"\"\n",
    "\n",
    "class SoftmaxRegression(object):\n",
    "    \n",
    "    \"\"\" Initialize parameters of the Regressor object \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, num_classes, lam):\n",
    "        \n",
    "        \"\"\" Initialize parameters of the Regressor object \"\"\"\n",
    "\n",
    "        self.input_size = input_size   # input vector size\n",
    "        self.num_classes = num_classes  # number of classes\n",
    "        self.lam = lam                  # weight decay parameter\n",
    "        \n",
    "        \"\"\" Randomly initialize the class weights \"\"\"\n",
    "        \n",
    "        rand = np.random.RandomState(int(time.time()))\n",
    "\n",
    "        rand = np.random.RandomState(10)\n",
    "        self.theta = 0.0005 * rand.rand(num_classes, input_size)\n",
    "        \n",
    "#         self.theta = 0.005 * np.asarray(rand.normal(size = (num_classes * input_size, 1)))\n",
    "        \n",
    "    def get_ground_truth(self, labels):\n",
    "        \"\"\" Returns the groundtruth matrix for a set of labels\"\"\"\n",
    "\n",
    "        \"\"\" Prepare data needed to construct ground truth matrix \"\"\"\n",
    "        labels = np.array(labels).flatten()\n",
    "        data = np.ones(len(labels))\n",
    "        indptr = np.arange(len(labels)+1)\n",
    "        \n",
    "        \"\"\" Compute the groundtruth matrix and return \"\"\"\n",
    "        \n",
    "        ground_truth = scipy.sparse.csr_matrix((data, labels, indptr))\n",
    "        ground_truth = np.transpose(ground_truth.todense())\n",
    "        \n",
    "        return ground_truth\n",
    "    \n",
    "    def softmax_cost(self, theta, input, labels):\n",
    "        \"\"\" Returns the cost and gradient of 'theta' at a particular 'theta' \"\"\"\n",
    "        \n",
    "        \"\"\" Compute the groundtruth matrix \"\"\"\n",
    "        ground_truth = self.get_ground_truth(labels)\n",
    "        \n",
    "        \"\"\" Reshape 'theta' for ease of computation \"\"\"\n",
    "        \n",
    "        theta = theta.reshape(self.num_classes, self.input_size)\n",
    "        \n",
    "        \"\"\" Compute the class probabilities for each example \"\"\"\n",
    "        \n",
    "        print 'X', input\n",
    "        print 'X.T[0]', input.T[0]\n",
    "        print 'X.shape', input.shape\n",
    "        print 'X.sum()', input.sum()\n",
    "        print 'theta', theta\n",
    "        print 'theta.shape', theta.shape\n",
    "        print 'theta.sum()', theta.sum()\n",
    "        \n",
    "        theta_x = np.dot(theta, input)\n",
    "        print 'theta_x', theta_x\n",
    "        print 'theta_x.sum()', theta_x.sum()\n",
    "        print 'theta_x.shape', theta_x.shape\n",
    "        hypothesis = np.exp(theta_x)\n",
    "        print 'h', hypothesis\n",
    "        print 'summation', np.sum(hypothesis, axis = 0)\n",
    "        probabilities = hypothesis / np.sum(hypothesis, axis = 0)\n",
    "        print 'probabilities', probabilities\n",
    "        \"\"\" Compute the traditional cost term \"\"\"\n",
    "        \n",
    "        cost_examples = np.multiply(ground_truth, np.log(probabilities))\n",
    "        traditional_cost = -(np.sum(cost_examples) / input.shape[1])\n",
    "        \n",
    "        \"\"\" Compute the weight decay term \"\"\"\n",
    "        \n",
    "        theta_squared = np.multiply(theta, theta)\n",
    "        weight_decay = 0.5 * self.lam * np.sum(theta_squared)\n",
    "        \n",
    "        \"\"\" Add both terms to get the cost \"\"\"\n",
    "        cost = traditional_cost + weight_decay\n",
    "        \n",
    "        \"\"\" Compute the unroll 'theta' gradient \"\"\"\n",
    "        \n",
    "        theta_grad = -np.dot(ground_truth - probabilities, np.transpose(input))\n",
    "        theta_grad = theta_grad / input.shape[1] + self.lam * theta\n",
    "        theta_grad = np.array(theta_grad)\n",
    "        theta_grad = theta_grad.flatten()\n",
    "        \n",
    "        return [cost, theta_grad]\n",
    "    \n",
    "    def softmax_predict(self, theta, input):\n",
    "        \n",
    "        \"\"\" Returns predicted classes for a set of inputs \"\"\"\n",
    "        \n",
    "        \"\"\" Reshape 'theta' for ease of computation \"\"\"\n",
    "        \n",
    "        theta = theta.reshape(self.num_classes, self.input_size)\n",
    "        \n",
    "        \"\"\" Compute the class probabilities for each example \"\"\"\n",
    "        \n",
    "        theta_x = np.dot(theta, input)\n",
    "        hypothesis = np.exp(theta_x)\n",
    "        probabilities = hypothesis / np.sum(hypothesis, axis = 0)\n",
    "        \n",
    "        \"\"\" Give the predictions based on probability values \"\"\"\n",
    "        \n",
    "        predictions = np.zeros((input.shape[1], 1))\n",
    "        predictions[:,0] = np.argmax(probabilities, axis=0)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "def load_mnist_images(file_name):\n",
    "\n",
    "    \"\"\" Open the file \"\"\"\n",
    "\n",
    "    image_file = open(file_name, 'rb')\n",
    "\n",
    "    \"\"\" Read header information from the file \"\"\"\n",
    "\n",
    "    head1 = image_file.read(4)\n",
    "    head2 = image_file.read(4)\n",
    "    head3 = image_file.read(4)\n",
    "    head4 = image_file.read(4)\n",
    "\n",
    "    \"\"\" Format the header information for useful data \"\"\"\n",
    "\n",
    "    num_examples = struct.unpack('>I', head2)[0]\n",
    "    num_rows     = struct.unpack('>I', head3)[0]\n",
    "    num_cols     = struct.unpack('>I', head4)[0]\n",
    "    \n",
    "\n",
    "    \"\"\" Initialize dataset as array of zeros \"\"\"\n",
    "\n",
    "    dataset = np.zeros((num_rows * num_cols, num_examples))\n",
    "\n",
    "    \"\"\" Read the actual image data \"\"\"\n",
    "\n",
    "    images_raw = array.array('B', image_file.read())\n",
    "    image_file.close()\n",
    "\n",
    "    \"\"\" Arrange the data in columns \"\"\"\n",
    "\n",
    "    for i in range(num_examples):\n",
    "\n",
    "        limit1 = num_rows * num_cols * i\n",
    "        limit2 = num_rows * num_cols * (i + 1)\n",
    "\n",
    "        dataset[:, i] = images_raw[limit1 : limit2]\n",
    "\n",
    "    \"\"\" Normalize and return the dataset \"\"\"\n",
    "\n",
    "    return dataset / 255\n",
    "\n",
    "def load_mnist_labels(file_name):\n",
    "\n",
    "    \"\"\" Open the file \"\"\"\n",
    "\n",
    "    label_file = open(file_name, 'rb')\n",
    "\n",
    "    \"\"\" Read header information from the file \"\"\"\n",
    "\n",
    "    head1 = label_file.read(4)\n",
    "    head2 = label_file.read(4)\n",
    "\n",
    "    \"\"\" Format the header information for useful data \"\"\"\n",
    "    \n",
    "    num_examples = struct.unpack('>I', head2)[0]\n",
    "    \n",
    "    \"\"\" Initialize data labels as array of zeros \"\"\"\n",
    "\n",
    "    labels = np.zeros((num_examples, 1), dtype = np.int)\n",
    "\n",
    "    \"\"\" Read the label data \"\"\"\n",
    "\n",
    "    labels_raw = array.array('b', label_file.read())\n",
    "    label_file.close()\n",
    "\n",
    "    \"\"\" Copy and return the label data \"\"\"\n",
    "\n",
    "    labels[:, 0] = labels_raw[:]\n",
    "\n",
    "    return labels\n",
    "        \n",
    "def execute_softmax_regression():\n",
    "\n",
    "    \"\"\" Initialize parameters of the Regressor \"\"\"\n",
    "\n",
    "    input_size = 784       # input vector size\n",
    "    num_classes = 10       # number of classes\n",
    "    lam = 0.0001           # weight decay parameter\n",
    "    max_iterations = 100   # number of optimization iterations\n",
    "\n",
    "    \"\"\" Load MNIST training images and labels \"\"\"\n",
    "\n",
    "    training_data = load_mnist_images('./train-images-idx3-ubyte')\n",
    "    training_labels = load_mnist_labels('./train-labels-idx1-ubyte')\n",
    "\n",
    "    \"\"\" Initialize Softmax Regressor with the above parameters \"\"\"\n",
    "\n",
    "    regressor = SoftmaxRegression(input_size, num_classes, lam)\n",
    "    \n",
    "    \"\"\" Run the L-BFGS algorithm to get the optimal parameter values \"\"\"\n",
    "    \n",
    "    opt_solution = scipy.optimize.minimize(\n",
    "        regressor.softmax_cost,\n",
    "        regressor.theta,\n",
    "        args = (\n",
    "            training_data,\n",
    "            training_labels,\n",
    "        ),\n",
    "        method = 'L-BFGS-B',\n",
    "        jac = True,\n",
    "        options = {\n",
    "            'maxiter': max_iterations\n",
    "        }\n",
    "    )\n",
    "    opt_theta = opt_solution.x\n",
    "\n",
    "    \"\"\" Load MNIST test images and labels \"\"\"\n",
    "\n",
    "    test_data = load_mnist_images('./t10k-images-idx3-ubyte')\n",
    "    test_labels = load_mnist_labels('./t10k-labels-idx1-ubyte')\n",
    "\n",
    "    \"\"\" Obtain predictions from the trained model \"\"\"\n",
    "\n",
    "    predictions = regressor.softmax_predict(opt_theta, test_data)\n",
    "\n",
    "    \"\"\" Print accuracy of the trained model \"\"\"\n",
    "\n",
    "    correct = test_labels[:, 0] == predictions[:, 0]\n",
    "    print \"\"\"Accuray :\"\"\", np.mean(correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "X.T[0] [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.01176471\n",
      "  0.07058824  0.07058824  0.07058824  0.49411765  0.53333333  0.68627451\n",
      "  0.10196078  0.65098039  1.          0.96862745  0.49803922  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.11764706  0.14117647  0.36862745\n",
      "  0.60392157  0.66666667  0.99215686  0.99215686  0.99215686  0.99215686\n",
      "  0.99215686  0.88235294  0.6745098   0.99215686  0.94901961  0.76470588\n",
      "  0.25098039  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.19215686\n",
      "  0.93333333  0.99215686  0.99215686  0.99215686  0.99215686  0.99215686\n",
      "  0.99215686  0.99215686  0.99215686  0.98431373  0.36470588  0.32156863\n",
      "  0.32156863  0.21960784  0.15294118  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.07058824  0.85882353  0.99215686  0.99215686  0.99215686\n",
      "  0.99215686  0.99215686  0.77647059  0.71372549  0.96862745  0.94509804\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.31372549  0.61176471\n",
      "  0.41960784  0.99215686  0.99215686  0.80392157  0.04313725  0.\n",
      "  0.16862745  0.60392157  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.05490196  0.00392157  0.60392157  0.99215686  0.35294118  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.54509804  0.99215686  0.74509804  0.00784314\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.04313725  0.74509804  0.99215686\n",
      "  0.2745098   0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.1372549\n",
      "  0.94509804  0.88235294  0.62745098  0.42352941  0.00392157  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.31764706  0.94117647  0.99215686  0.99215686  0.46666667  0.09803922\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.17647059  0.72941176  0.99215686  0.99215686\n",
      "  0.58823529  0.10588235  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.0627451   0.36470588\n",
      "  0.98823529  0.99215686  0.73333333  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.97647059  0.99215686  0.97647059  0.25098039  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.18039216  0.50980392\n",
      "  0.71764706  0.99215686  0.99215686  0.81176471  0.00784314  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.15294118  0.58039216  0.89803922\n",
      "  0.99215686  0.99215686  0.99215686  0.98039216  0.71372549  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.09411765  0.44705882  0.86666667  0.99215686\n",
      "  0.99215686  0.99215686  0.99215686  0.78823529  0.30588235  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.09019608  0.25882353  0.83529412  0.99215686  0.99215686\n",
      "  0.99215686  0.99215686  0.77647059  0.31764706  0.00784314  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.07058824  0.67058824  0.85882353  0.99215686  0.99215686  0.99215686\n",
      "  0.99215686  0.76470588  0.31372549  0.03529412  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.21568627  0.6745098   0.88627451  0.99215686  0.99215686  0.99215686\n",
      "  0.99215686  0.95686275  0.52156863  0.04313725  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.53333333  0.99215686  0.99215686  0.99215686  0.83137255\n",
      "  0.52941176  0.51764706  0.0627451   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "X.shape (784, 1000)\n",
      "X.sum() 100539.345098\n",
      "theta [[  3.85660322e-04   1.03759747e-05   3.16824117e-04 ...,   4.66530193e-04\n",
      "    2.79538175e-04   3.08552539e-04]\n",
      " [  2.34494602e-04   4.97414883e-04   4.66736855e-04 ...,   3.08559443e-04\n",
      "    2.61600180e-04   1.31760154e-04]\n",
      " [  2.66439515e-04   1.67756526e-04   1.53673573e-04 ...,   5.97942741e-05\n",
      "    1.59763830e-04   2.88624047e-04]\n",
      " ..., \n",
      " [  4.30791245e-04   3.23250704e-04   1.18635170e-04 ...,   4.50958641e-04\n",
      "    2.83464425e-04   1.39533453e-04]\n",
      " [  2.12040461e-04   6.69079080e-05   3.39008463e-04 ...,   4.56860688e-04\n",
      "    3.74694615e-04   2.45380228e-04]\n",
      " [  3.84250382e-04   1.95418337e-05   1.75991613e-04 ...,   4.98374494e-04\n",
      "    1.15055453e-04   4.47175715e-04]]\n",
      "theta.shape (10, 784)\n",
      "theta.sum() 1.91790253931\n",
      "theta_x [[ 0.02531068  0.02777801  0.02054312 ...,  0.02871088  0.02286037\n",
      "   0.02679531]\n",
      " [ 0.0259953   0.03345168  0.02078479 ...,  0.03257336  0.02351792\n",
      "   0.02570013]\n",
      " [ 0.02725775  0.0284402   0.01883031 ...,  0.02958965  0.02085227\n",
      "   0.02413798]\n",
      " ..., \n",
      " [ 0.02981815  0.0312936   0.01971448 ...,  0.03174765  0.02178616\n",
      "   0.02369264]\n",
      " [ 0.02528859  0.02976467  0.0184736  ...,  0.03316596  0.02094077\n",
      "   0.02567296]\n",
      " [ 0.02627654  0.03057921  0.0206085  ...,  0.03151797  0.02418878\n",
      "   0.02610247]]\n",
      "theta_x.sum() 249.66648039\n",
      "theta_x.shape (10, 1000)\n",
      "h [[ 1.02563372  1.02816742  1.02075558 ...,  1.02912701  1.02312367\n",
      "   1.02715753]\n",
      " [ 1.02633613  1.03401747  1.02100229 ...,  1.03310968  1.02379665\n",
      "   1.02603322]\n",
      " [ 1.02763264  1.02884848  1.01900872 ...,  1.03003177  1.0210712\n",
      "   1.02443166]\n",
      " ..., \n",
      " [ 1.03026716  1.0317884   1.01991009 ...,  1.03225699  1.02202521\n",
      "   1.02397554]\n",
      " [ 1.02561106  1.03021206  1.01864529 ...,  1.03372208  1.02116157\n",
      "   1.02600535]\n",
      " [ 1.02662482  1.03105156  1.02082232 ...,  1.03201992  1.0244837\n",
      "   1.02644612]]\n",
      "summation [ 10.27224788  10.30621214  10.19132154  10.16911001  10.23013885\n",
      "  10.29541453  10.17320704  10.35473903  10.10862621  10.22206494\n",
      "  10.27956443  10.14242872  10.351644    10.28165623  10.11692418\n",
      "  10.24911958  10.24469617  10.272963    10.13294621  10.17664217\n",
      "  10.33577511  10.34489463  10.15723256  10.16366891  10.21628396\n",
      "  10.40354704  10.1316409   10.4536763   10.41846616  10.15879895\n",
      "  10.255651    10.32479748  10.16926997  10.21240406  10.36557995\n",
      "  10.15883249  10.3171777   10.37571571  10.21709232  10.26488733\n",
      "  10.13996792  10.27828488  10.12445756  10.18037388  10.17128706\n",
      "  10.23850245  10.22493561  10.21941093  10.16734768  10.3229126\n",
      "  10.18417073  10.44494661  10.28014626  10.16582063  10.23141595\n",
      "  10.31964891  10.41275223  10.19973651  10.33123691  10.16473562\n",
      "  10.29180744  10.18100768  10.30081095  10.45613415  10.2549154\n",
      "  10.16582443  10.2702853   10.15247005  10.2371632   10.42224773\n",
      "  10.21835809  10.20611868  10.10782864  10.26228206  10.25677886\n",
      "  10.33746826  10.25937061  10.16810284  10.19755227  10.23186848\n",
      "  10.25745843  10.36860017  10.40275103  10.26530071  10.1852116\n",
      "  10.25378515  10.21265737  10.27654529  10.33253455  10.24652383\n",
      "  10.29113774  10.25668688  10.15030209  10.29305562  10.27181594\n",
      "  10.3734707   10.17995677  10.29003719  10.21126382  10.12700024\n",
      "  10.17728381  10.23010342  10.11401877  10.18935909  10.11411568\n",
      "  10.19150045  10.2593701   10.3099401   10.27945681  10.20954736\n",
      "  10.24476522  10.45798889  10.11935135  10.20494823  10.39245613\n",
      "  10.20908376  10.25386644  10.3944284   10.24332471  10.42173779\n",
      "  10.39341279  10.44512675  10.23545525  10.24299831  10.09491216\n",
      "  10.26151553  10.26909713  10.23242102  10.19916676  10.31299125\n",
      "  10.22074397  10.27272322  10.1759191   10.18120073  10.23601241\n",
      "  10.3274445   10.20062424  10.27022969  10.27537993  10.24132683\n",
      "  10.13487964  10.22335733  10.18005331  10.24650107  10.18351784\n",
      "  10.18974268  10.28604513  10.28239682  10.17622562  10.34465639\n",
      "  10.26258472  10.26254967  10.14603436  10.16076614  10.2134147\n",
      "  10.29318098  10.25852409  10.31657989  10.15255128  10.29701609\n",
      "  10.20606624  10.35934846  10.21203025  10.23755195  10.36183715\n",
      "  10.31286385  10.20821854  10.24753399  10.30810523  10.3728948\n",
      "  10.2109333   10.3399868   10.24472105  10.1514749   10.11944979\n",
      "  10.22473114  10.19422515  10.21027292  10.22420721  10.35941554\n",
      "  10.15939681  10.34333293  10.26279275  10.23966644  10.1356306\n",
      "  10.28629785  10.22797714  10.39166336  10.27643312  10.32244998\n",
      "  10.28452853  10.16631305  10.31098538  10.26380109  10.28748488\n",
      "  10.22015128  10.27113001  10.24099522  10.27877603  10.26527196\n",
      "  10.17447003  10.18202592  10.25943209  10.31407588  10.23224328\n",
      "  10.17980231  10.35378785  10.28932368  10.18102088  10.37671362\n",
      "  10.16414001  10.18512457  10.15670976  10.38050268  10.27414287\n",
      "  10.32713633  10.26970232  10.19834476  10.25244951  10.25790087\n",
      "  10.35712883  10.34977631  10.38004529  10.25431248  10.25227704\n",
      "  10.33471284  10.21331876  10.21868251  10.17808022  10.36534136\n",
      "  10.18515846  10.16722844  10.16510101  10.31165591  10.26366665\n",
      "  10.30234362  10.29490205  10.20795783  10.23626596  10.23569481\n",
      "  10.18101994  10.28405648  10.37482197  10.24006356  10.40103702\n",
      "  10.31972512  10.22773016  10.18506488  10.19243611  10.33688561\n",
      "  10.24955866  10.1975785   10.28620537  10.38266946  10.21890668\n",
      "  10.32699569  10.17433249  10.22048342  10.15213631  10.23123221\n",
      "  10.15277179  10.2826793   10.20070862  10.2691351   10.20274143\n",
      "  10.35765464  10.28900881  10.19054995  10.20931982  10.15295489\n",
      "  10.08404577  10.19468114  10.26205278  10.22660854  10.21180245\n",
      "  10.21588501  10.09869878  10.39122146  10.245297    10.28655924\n",
      "  10.17859823  10.3064636   10.16334691  10.42376269  10.27810308\n",
      "  10.1875834   10.4528403   10.18324139  10.18461187  10.17648596\n",
      "  10.14176023  10.25430011  10.20714386  10.44735833  10.36316426\n",
      "  10.23974838  10.30464708  10.20594325  10.33701228  10.34066897\n",
      "  10.21630915  10.22019178  10.28902697  10.42449454  10.1362663\n",
      "  10.21888289  10.28735027  10.19580202  10.34864526  10.13754269\n",
      "  10.11022985  10.27364276  10.32646709  10.20820641  10.18516014\n",
      "  10.17496999  10.17655421  10.34264273  10.22161301  10.23078139\n",
      "  10.32611915  10.26134344  10.20294004  10.28157344  10.25123413\n",
      "  10.37284488  10.27281163  10.27477249  10.34581072  10.24404385\n",
      "  10.2535725   10.25683387  10.21994434  10.32088967  10.25267099\n",
      "  10.18138321  10.18907239  10.2622168   10.17041601  10.36267349\n",
      "  10.22489057  10.32210679  10.15987971  10.26934032  10.18231363\n",
      "  10.17259422  10.22412678  10.34676844  10.33481297  10.24163696\n",
      "  10.228049    10.19304793  10.34198312  10.21927866  10.16035007\n",
      "  10.19456474  10.18844788  10.21092474  10.12695717  10.32650248\n",
      "  10.30299224  10.30200739  10.21805565  10.18833776  10.16191889\n",
      "  10.32911519  10.11715746  10.29743737  10.21534025  10.20998696\n",
      "  10.17781158  10.26706602  10.17833044  10.19155036  10.29527484\n",
      "  10.37410563  10.20216442  10.29562549  10.30870205  10.17673394\n",
      "  10.28090577  10.35010375  10.18360576  10.2479585   10.19958327\n",
      "  10.43428424  10.31016433  10.22231588  10.12982687  10.22405477\n",
      "  10.28101867  10.344411    10.28005401  10.29706157  10.15418751\n",
      "  10.28188646  10.16931145  10.1620215   10.11497495  10.44948077\n",
      "  10.30999924  10.2154117   10.19429935  10.21953139  10.28810483\n",
      "  10.26738605  10.15674105  10.20474375  10.11678556  10.22927025\n",
      "  10.28423884  10.22541473  10.11789333  10.17347597  10.25958607\n",
      "  10.31991056  10.18857768  10.15310587  10.10182565  10.22257859\n",
      "  10.1805435   10.30022384  10.15237318  10.21165526  10.31616098\n",
      "  10.26111988  10.36706126  10.48834846  10.22003657  10.42728186\n",
      "  10.19107703  10.27345524  10.21999693  10.2667218   10.17039296\n",
      "  10.35257484  10.13759748  10.18390468  10.28422241  10.28228454\n",
      "  10.4296442   10.18394561  10.17496808  10.16086587  10.15294149\n",
      "  10.31423694  10.22366327  10.16744718  10.3020498   10.28810629\n",
      "  10.15467068  10.36417102  10.31225259  10.30498195  10.09430075\n",
      "  10.16247796  10.1898913   10.27938687  10.408019    10.25730598\n",
      "  10.20734238  10.24209495  10.43282267  10.15193988  10.41946172\n",
      "  10.31418477  10.09605531  10.2808703   10.14642203  10.31453941\n",
      "  10.14140884  10.24482796  10.15320865  10.33268502  10.22425382\n",
      "  10.1393544   10.17956563  10.30940474  10.27990537  10.28774033\n",
      "  10.32435873  10.21574872  10.20144207  10.27829936  10.10712528\n",
      "  10.28653741  10.28337026  10.20850193  10.29842288  10.24691802\n",
      "  10.29439661  10.15724819  10.20382784  10.25897029  10.30357736\n",
      "  10.36172141  10.25858898  10.20410809  10.17828434  10.2721156\n",
      "  10.17536231  10.18750204  10.13513537  10.23178192  10.35627881\n",
      "  10.24362244  10.25798744  10.16395295  10.16617043  10.30374264\n",
      "  10.12324095  10.21591103  10.30574478  10.19594084  10.1651263\n",
      "  10.35725024  10.2697486   10.28757934  10.19210157  10.40241633\n",
      "  10.27195284  10.31317465  10.27278721  10.15471222  10.30612119\n",
      "  10.25472678  10.42330974  10.25381078  10.43590197  10.24601288\n",
      "  10.2174827   10.199164    10.28827734  10.15884838  10.23626806\n",
      "  10.18024328  10.17196289  10.21926246  10.11696758  10.35929097\n",
      "  10.17028835  10.22857671  10.36182188  10.18360564  10.31615845\n",
      "  10.27504551  10.24094007  10.22858472  10.36924563  10.27635308\n",
      "  10.22881289  10.2950112   10.20379351  10.15362894  10.38870314\n",
      "  10.29084704  10.20190017  10.31787561  10.13489377  10.29720028\n",
      "  10.16186244  10.25541286  10.21811452  10.28616135  10.23939813\n",
      "  10.34797772  10.18452581  10.19716326  10.28249015  10.25146964\n",
      "  10.42494063  10.2891202   10.15107775  10.16134822  10.15321465\n",
      "  10.22081927  10.15923455  10.3743658   10.20783585  10.18474565\n",
      "  10.20558822  10.27217548  10.30068586  10.19737552  10.15363009\n",
      "  10.18557664  10.14177706  10.156548    10.16086509  10.24721783\n",
      "  10.17559085  10.37247322  10.17026769  10.157763    10.25669368\n",
      "  10.19828159  10.36671946  10.31312326  10.3076127   10.21597425\n",
      "  10.15941999  10.18709095  10.25143981  10.33531221  10.0741335\n",
      "  10.19490659  10.32094177  10.28473565  10.23569215  10.17991647\n",
      "  10.22638067  10.16897408  10.29226519  10.25686751  10.24347124\n",
      "  10.25863792  10.32017862  10.22667845  10.12182384  10.2343958\n",
      "  10.43053657  10.19901968  10.3584522   10.33753235  10.20903998\n",
      "  10.26279356  10.35066138  10.20778942  10.18771875  10.30243943\n",
      "  10.13282739  10.2155114   10.2634563   10.34737687  10.12787947\n",
      "  10.31683435  10.14142602  10.14480067  10.12603418  10.34550133\n",
      "  10.24894305  10.22490027  10.34641218  10.34122724  10.16743779\n",
      "  10.33001848  10.18206205  10.14557882  10.1154296   10.30489272\n",
      "  10.20733253  10.24243117  10.22901089  10.19217135  10.21511863\n",
      "  10.24565918  10.38294223  10.28428423  10.28244622  10.283526\n",
      "  10.15855432  10.19842846  10.26615908  10.21526738  10.26636921\n",
      "  10.39114989  10.25326264  10.31194867  10.31305077  10.37665351\n",
      "  10.39606051  10.21755931  10.31056758  10.31267552  10.14249495\n",
      "  10.30207657  10.13517192  10.29881079  10.13806734  10.28514335\n",
      "  10.20404473  10.36479823  10.12519777  10.28217578  10.31761853\n",
      "  10.27551053  10.15992897  10.27108573  10.21985817  10.37527733\n",
      "  10.23282151  10.21686843  10.25004776  10.28206347  10.21431929\n",
      "  10.27191338  10.17853435  10.28909719  10.17379576  10.30289197\n",
      "  10.18030878  10.36131362  10.31775631  10.26783162  10.3089804\n",
      "  10.28280883  10.22450256  10.24591381  10.20064907  10.34198521\n",
      "  10.13960453  10.188641    10.40700195  10.39977821  10.23030624\n",
      "  10.31397623  10.35699598  10.32170233  10.16263695  10.39137769\n",
      "  10.19128196  10.3461948   10.29221922  10.27486873  10.29008176\n",
      "  10.30300359  10.21407697  10.25213597  10.1404739   10.31255104\n",
      "  10.25764427  10.27953361  10.32031676  10.36136044  10.36856344\n",
      "  10.30492826  10.16555147  10.35726738  10.09244755  10.35488897\n",
      "  10.2264698   10.25237087  10.19794458  10.43567362  10.16552298\n",
      "  10.4161022   10.17424946  10.15947797  10.25878327  10.28271438\n",
      "  10.1827169   10.33172132  10.3173066   10.26561136  10.10488664\n",
      "  10.29859152  10.59616663  10.33710393  10.33754246  10.34433126\n",
      "  10.21780846  10.29714157  10.17327266  10.35648356  10.29971169\n",
      "  10.20393097  10.34905805  10.27714464  10.21128354  10.38194426\n",
      "  10.13624254  10.29193572  10.42332239  10.21957504  10.33432933\n",
      "  10.18205375  10.33037862  10.3333023   10.10342911  10.18035113\n",
      "  10.14535962  10.4192273   10.16150624  10.18495985  10.22931435\n",
      "  10.28486109  10.12871122  10.35452665  10.23024668  10.27456844\n",
      "  10.31874994  10.33906069  10.28943087  10.27745614  10.31814733\n",
      "  10.24246283  10.17214615  10.29661468  10.19341319  10.2891748\n",
      "  10.27286322  10.25327699  10.28284616  10.25641044  10.25625241\n",
      "  10.2561423   10.29188186  10.22664036  10.15414841  10.17030411\n",
      "  10.31987742  10.27002274  10.20688442  10.28709556  10.40336664\n",
      "  10.29745041  10.26426111  10.32407124  10.23504264  10.26248212\n",
      "  10.21492391  10.22303021  10.13964389  10.29034291  10.15238252\n",
      "  10.38544899  10.32639055  10.22873795  10.22587188  10.34242988\n",
      "  10.30171044  10.36104998  10.18876881  10.19007525  10.20334888\n",
      "  10.17901437  10.23642487  10.29840439  10.12707727  10.24804007\n",
      "  10.28872294  10.3308463   10.23820746  10.2403361   10.28911454\n",
      "  10.31872503  10.28013551  10.28887309  10.25403514  10.39370935\n",
      "  10.20599809  10.27947071  10.24602188  10.23127964  10.23742049\n",
      "  10.29191685  10.17241672  10.3090791   10.17760138  10.42172379\n",
      "  10.33517903  10.29316636  10.30646081  10.18922008  10.12369572\n",
      "  10.3265088   10.26724823  10.30239036  10.14173592  10.29094015\n",
      "  10.16946978  10.15905276  10.44100958  10.37038908  10.39548135\n",
      "  10.39838208  10.17762773  10.25304407  10.16681956  10.1741448\n",
      "  10.25197249  10.3110051   10.25668109  10.31256389  10.16874046\n",
      "  10.36624122  10.32583598  10.34026295  10.19523277  10.30126389\n",
      "  10.32493883  10.16354909  10.15682566  10.40760128  10.31192868\n",
      "  10.44841109  10.3593187   10.21803044  10.22404775  10.19050916\n",
      "  10.12614325  10.26926738  10.26853801  10.30832884  10.2469217\n",
      "  10.17535592  10.24934556  10.40891673  10.22087647  10.40397185\n",
      "  10.23861714  10.27900121  10.20051403  10.34338799  10.25666272\n",
      "  10.17878799  10.36622849  10.33822495  10.25608686  10.16493847\n",
      "  10.21243886  10.22660508  10.12132942  10.33025632  10.31487725\n",
      "  10.36164949  10.28202894  10.34848257  10.20365128  10.26507652\n",
      "  10.31590689  10.30170996  10.2062747   10.17104209  10.27720246\n",
      "  10.20204978  10.17445537  10.20532433  10.20921732  10.17710381\n",
      "  10.24284388  10.10362873  10.3678806   10.25348751  10.42706291\n",
      "  10.18394004  10.37451923  10.14886146  10.2773596   10.3658876\n",
      "  10.35450405  10.15461455  10.26252797  10.2837954   10.29308461\n",
      "  10.1994498   10.26549408  10.26215496  10.29600031  10.24794467\n",
      "  10.32723351  10.12391158  10.19219412  10.27816034  10.21740829\n",
      "  10.26816351  10.19300333  10.2513879   10.15860352  10.2923039\n",
      "  10.23929193  10.16799846  10.42892708  10.25924973  10.29633556\n",
      "  10.34934605  10.26278422  10.22925873  10.10454452  10.30730686\n",
      "  10.20737205  10.35784433  10.18320107  10.29783343  10.25706914\n",
      "  10.19946935  10.35773087  10.24679818  10.26889772  10.35031242\n",
      "  10.29612096  10.27250379  10.28363153  10.10605561  10.26221664\n",
      "  10.30060718  10.20498996  10.31455043  10.22146391  10.25497913]\n",
      "probabilities [[ 0.09984511  0.09976191  0.1001593  ...,  0.0997743   0.10009561\n",
      "   0.10016184]\n",
      " [ 0.09991349  0.10032954  0.1001835  ...,  0.10016042  0.10016145\n",
      "   0.1000522 ]\n",
      " [ 0.1000397   0.09982799  0.09998789 ...,  0.09986201  0.09989481\n",
      "   0.09989603]\n",
      " ..., \n",
      " [ 0.10029617  0.10011325  0.10007633 ...,  0.10007775  0.09998814\n",
      "   0.09985155]\n",
      " [ 0.0998429   0.0999603   0.09995223 ...,  0.10021979  0.09990365\n",
      "   0.10004948]\n",
      " [ 0.09994159  0.10004176  0.10016584 ...,  0.10005477  0.10022867\n",
      "   0.10009246]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,60000) (10,1000) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ed1809afc70f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     options = {\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;34m'maxiter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     }\n\u001b[1;32m     32\u001b[0m )\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 380\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, **unknown_options)\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0mn_function_evals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b99e21554ccc>\u001b[0m in \u001b[0;36msoftmax_cost\u001b[0;34m(self, theta, input, labels)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;34m\"\"\" Compute the traditional cost term \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mcost_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mtraditional_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_examples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,60000) (10,1000) "
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" Initialize parameters of the Regressor \"\"\"\n",
    "\n",
    "input_size = 784       # input vector size\n",
    "num_classes = 10       # number of classes\n",
    "lam = 0.0001           # weight decay parameter\n",
    "max_iterations = 1   # number of optimization iterations\n",
    "\n",
    "\"\"\" Load MNIST training images and labels \"\"\"\n",
    "\n",
    "training_data = load_mnist_images('./train-images-idx3-ubyte')[:,:1000]\n",
    "training_labels = load_mnist_labels('./train-labels-idx1-ubyte')[:,:1000]\n",
    "\n",
    "\"\"\" Initialize Softmax Regressor with the above parameters \"\"\"\n",
    "\n",
    "regressor = SoftmaxRegression(input_size, num_classes, lam)\n",
    "\n",
    "\"\"\" Run the L-BFGS algorithm to get the optimal parameter values \"\"\"\n",
    "\n",
    "opt_solution = scipy.optimize.minimize(\n",
    "    regressor.softmax_cost,\n",
    "    regressor.theta,\n",
    "    args = (\n",
    "        training_data,\n",
    "        training_labels,\n",
    "    ),\n",
    "    method = 'L-BFGS-B',\n",
    "    jac = True,\n",
    "    options = {\n",
    "        'maxiter': max_iterations\n",
    "    }\n",
    ")\n",
    "# opt_theta = opt_solution.x\n",
    "\n",
    "# \"\"\" Load MNIST test images and labels \"\"\"\n",
    "\n",
    "# test_data = load_mnist_images('./t10k-images-idx3-ubyte')\n",
    "# test_labels = load_mnist_labels('./t10k-labels-idx1-ubyte')\n",
    "\n",
    "# \"\"\" Obtain predictions from the trained model \"\"\"\n",
    "\n",
    "# predictions = regressor.softmax_predict(opt_theta, test_data)\n",
    "\n",
    "# \"\"\" Print accuracy of the trained model \"\"\"\n",
    "\n",
    "# correct = test_labels[:, 0] == predictions[:, 0]\n",
    "# print \"\"\"Accuray :\"\"\", np.mean(correct)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ..., 5 6 8]\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# def get_ground_truth(self, labels):\n",
    "#     \"\"\" Returns the groundtruth matrix for a set of labels\"\"\"\n",
    "\n",
    "#     \"\"\" Prepare data needed to construct ground truth matrix \"\"\"\n",
    "#     labels = np.array(labels).flatten()\n",
    "#     data = np.ones(len(labels))\n",
    "#     indptr = np.arange(len(labels)+1)\n",
    "\n",
    "#     \"\"\" Compute the groundtruth matrix and return \"\"\"\n",
    "\n",
    "#     ground_truth = scipy.sparse.csr_matrix((data, labels, indptr))\n",
    "#     ground_truth = np.transpose(ground_truth.todense())\n",
    "\n",
    "#     return ground_truth\n",
    "\n",
    "# training_labels\n",
    "\n",
    "print labels\n",
    "labels = np.array(training_labels).flatten()\n",
    "data = np.ones(len(labels))\n",
    "indptr = np.arange(len(labels)+1)\n",
    "# print indptr\n",
    "\n",
    "ground_truth = scipy.sparse.csr_matrix((data, labels, indptr))\n",
    "# print ground_truth.todense()\n",
    "ground_truth = np.transpose(ground_truth.todense()).T\n",
    "# print ground_truth[0]\n",
    "print ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y):\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    K = len(np.unique(y))\n",
    "    one_hot = np.zeros(shape=(m, K))\n",
    "    for i, row in enumerate(one_hot):\n",
    "        if i < 10:\n",
    "            idx = y[i]\n",
    "            row[idx] = 1\n",
    "    return one_hot\n",
    "# print to_one_hot(labels)[0]\n",
    "one_hot_labels = to_one_hot(labels)\n",
    "print one_hot_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Initialize Softmax Regressor with the above parameters '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_size = 784       # input vector size\n",
    "num_classes = 10       # number of classes\n",
    "lam = 0.0001           # weight decay parameter\n",
    "max_iterations = 100   # number of optimization iterations\n",
    "\n",
    "\"\"\" Load MNIST training images and labels \"\"\"\n",
    "\n",
    "training_data = load_mnist_images('./train-images-idx3-ubyte')\n",
    "training_labels = load_mnist_labels('./train-labels-idx1-ubyte')\n",
    "\n",
    "\"\"\" Initialize Softmax Regressor with the above parameters \"\"\"\n",
    "\n",
    "# regressor = SoftmaxRegression(input_size, num_classes, lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressor.softmax_cost(self, theta, training_data, training_labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 785)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b0502feefd2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmatrix_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mm_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./mnist_train.csv')[:1000]\n",
    "# test = pd.read_csv('./mnist_test.csv', header=None)\n",
    "\n",
    "matrix = df.as_matrix()\n",
    "print matrix.shape\n",
    "m = matrix.shape[0]\n",
    "y = matrix[:,0:1]\n",
    "X = matrix[:,1:]\n",
    "\n",
    "# matrix_test = test.as_matrix()\n",
    "# X_test = matrix_test[:,1:]\n",
    "# m_test = X_test.shape[0]\n",
    "# y_test = matrix_test[:,0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_of_features = X.shape[1]\n",
    "k = len(np.unique(y))\n",
    "rand = np.random.RandomState(10)\n",
    "theta = 0.0005 * rand.rand(n_of_features, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "X.T[0] [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  51 159 253 159  50   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84 252\n",
      " 253 122   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
      "  47  79 255 168   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0\n",
      "   0   0   0   0 253 252 165   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  57 252 252  63   0   0   0\n",
      "   0   0   0   0   0   0 253 252 195   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255 253\n",
      " 196   0   0   0   0   0   0   0   0   0   0   0  76 246 252 112   0   0\n",
      "   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0   0   0\n",
      "   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7 135\n",
      " 253 186  12   0   0   0   0   0   0   0   0   0   0   0  85 252 223   0\n",
      "   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
      " 252 173   0   0   0   0   0   0   0   0   0   0   0   0   0   0  86 253\n",
      " 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253\n",
      " 223 167  56   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  28 199 252 252 253 252 252 233\n",
      " 145   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "X.shape (784, 1000)\n",
      "X.sum() 25634175\n",
      "theta [[  3.85660322e-04   1.03759747e-05   3.16824117e-04 ...,   4.66530193e-04\n",
      "    2.79538175e-04   3.08552539e-04]\n",
      " [  2.34494602e-04   4.97414883e-04   4.66736855e-04 ...,   3.08559443e-04\n",
      "    2.61600180e-04   1.31760154e-04]\n",
      " [  2.66439515e-04   1.67756526e-04   1.53673573e-04 ...,   5.97942741e-05\n",
      "    1.59763830e-04   2.88624047e-04]\n",
      " ..., \n",
      " [  4.30791245e-04   3.23250704e-04   1.18635170e-04 ...,   4.50958641e-04\n",
      "    2.83464425e-04   1.39533453e-04]\n",
      " [  2.12040461e-04   6.69079080e-05   3.39008463e-04 ...,   4.56860688e-04\n",
      "    3.74694615e-04   2.45380228e-04]\n",
      " [  3.84250382e-04   1.95418337e-05   1.75991613e-04 ...,   4.98374494e-04\n",
      "    1.15055453e-04   4.47175715e-04]]\n",
      "theta.shape (10, 784)\n",
      "theta.sum() 1.91790253931\n",
      "theta_x [[ 7.08339261  5.23849615  4.13558312 ...,  5.82939387  6.8328044\n",
      "   6.00333485]\n",
      " [ 8.53017741  5.3001202   4.3652769  ...,  5.99706937  6.55353225\n",
      "   6.14876512]\n",
      " [ 7.25225128  4.80172892  4.64594513 ...,  5.31732967  6.15518455\n",
      "   5.07702501]\n",
      " ..., \n",
      " [ 7.97986899  5.0271919   4.9095439  ...,  5.55547127  6.04162307\n",
      "   6.57881962]\n",
      " [ 7.58998985  4.71076782  4.00131832 ...,  5.33989697  6.54660479\n",
      "   5.99652437]\n",
      " [ 7.79769889  5.25516703  4.38496978 ...,  6.16813784  6.6561298\n",
      "   6.79176922]]\n",
      "theta_x.sum() 63656.9045151\n",
      "theta_x.shape (10, 1000)\n",
      "h [[ 1192.00567913   188.38658363    62.52604073 ...,   340.15244128\n",
      "    927.78906354   404.77641231]\n",
      " [ 5065.34441846   200.36089215    78.67118128 ...,   402.2482248\n",
      "    701.71844316   468.1389345 ]\n",
      " [ 1411.27845732   121.72068055   104.16176589 ...,   203.83883824\n",
      "    471.15378552   160.29646623]\n",
      " ..., \n",
      " [ 2921.54828516   152.50416334   135.5775637  ...,   258.64882971\n",
      "    420.57510574   719.68931977]\n",
      " [ 1978.29343871   111.13746087    54.67017514 ...,   208.49122831\n",
      "    696.87411847   402.02905858]\n",
      " [ 2434.99235085   191.55347754    80.23579883 ...,   477.29647669\n",
      "    777.535889     890.48763759]]\n",
      "summation [  2.39572004e+04   1.32672912e+03   7.60332530e+02   3.38968520e+03\n",
      "   1.74908705e+04   8.29205080e+02   7.72008040e+04   1.61359845e+02\n",
      "   2.90877098e+03   1.20269464e+04   3.84971875e+02   7.26273677e+04\n",
      "   1.28417954e+04   1.99050210e+02   5.51731239e+03   5.11167415e+03\n",
      "   1.05302738e+04   3.03272102e+02   8.99810926e+02   5.48426815e+04\n",
      "   6.31301615e+04   5.46467948e+02   6.64463157e+02   2.44586074e+03\n",
      "   2.61418498e+05   2.84593843e+02   9.69835880e+05   4.05906244e+05\n",
      "   5.73588963e+02   6.83831937e+03   3.68836847e+04   7.61207184e+02\n",
      "   2.21362345e+03   1.06932605e+05   5.78768158e+02   3.10711529e+04\n",
      "   1.37596151e+05   2.47456770e+03   8.30592241e+03   3.61961797e+02\n",
      "   1.23826943e+04   2.36530015e+02   1.02199731e+03   8.08848391e+02\n",
      "   4.24858139e+03   3.27332678e+03   2.64236883e+03   7.07543921e+02\n",
      "   3.61979952e+04   1.08498080e+03   7.45057691e+05   1.21678514e+04\n",
      "   6.74515475e+02   3.44428553e+03   3.59062457e+04   3.25835405e+05\n",
      "   1.57843234e+03   4.52326042e+04   6.62373104e+02   1.62964799e+04\n",
      "   1.01471294e+03   2.08848017e+04   9.43190742e+05   6.75288465e+03\n",
      "   6.78491318e+02   9.92672279e+03   4.89828772e+02   4.16940680e+03\n",
      "   4.47109687e+05   2.57820881e+03   1.88809148e+03   1.58786171e+02\n",
      "   7.77862687e+03   6.94966300e+03   5.04237414e+04   7.70959706e+03\n",
      "   7.20362535e+02   1.53842927e+03   3.63101154e+03   7.27450010e+03\n",
      "   1.13418030e+05   2.74793205e+05   8.41017578e+03   1.09168467e+03\n",
      "   6.44619124e+03   2.28162063e+03   1.09472942e+04   4.45321030e+04\n",
      "   5.29950171e+03   1.65406532e+04   6.89225374e+03   4.64463705e+02\n",
      "   1.67603314e+04   1.04345106e+04   1.29707030e+05   9.58579890e+02\n",
      "   1.64772657e+04   2.18343799e+03   2.57877600e+02   9.29690509e+02\n",
      "   3.39201002e+03   1.85456574e+02   1.22986381e+03   1.85006468e+02\n",
      "   1.28334241e+03   7.33501982e+03   2.67785768e+04   1.20113346e+04\n",
      "   2.02143448e+03   5.04145922e+03   1.01789652e+06   2.13326783e+02\n",
      "   1.80889054e+03   1.95237344e+05   2.01742599e+03   6.25468318e+03\n",
      "   2.12530243e+05   5.01172713e+03   4.36445237e+05   2.11367153e+05\n",
      "   7.41305481e+05   4.02431057e+03   4.70490473e+03   1.13615313e+02\n",
      "   7.66362993e+03   9.43486828e+03   3.74950230e+03   1.59440783e+03\n",
      "   2.82634581e+04   2.71644010e+03   1.02790298e+04   8.91072169e+02\n",
      "   1.02922583e+03   4.16545813e+03   4.05120163e+04   1.69168253e+03\n",
      "   1.01255425e+04   1.09445705e+04   4.58918893e+03   3.15436984e+02\n",
      "   2.95093589e+03   9.89531554e+02   5.17828957e+03   1.17282579e+03\n",
      "   1.22907734e+03   1.47319058e+04   1.31410001e+04   8.87245980e+02\n",
      "   6.40945750e+04   7.71067640e+03   8.04962543e+03   4.17690758e+02\n",
      "   5.97230060e+02   2.26655164e+03   1.69210821e+04   7.19697986e+03\n",
      "   3.14967916e+04   4.87835832e+02   1.86886720e+04   2.03182129e+03\n",
      "   8.97481648e+04   2.16984863e+03   4.22047415e+03   9.94295947e+04\n",
      "   2.83064135e+04   1.96035586e+03   5.27173199e+03   2.49192092e+04\n",
      "   1.25214885e+05   2.17240123e+03   5.40209415e+04   4.94973051e+03\n",
      "   4.84394855e+02   2.14383496e+02   2.94414902e+03   1.41579613e+03\n",
      "   2.13394530e+03   3.10581301e+03   9.15271517e+04   5.83886658e+02\n",
      "   6.02780704e+04   8.10776877e+03   4.24875232e+03   3.20333450e+02\n",
      "   1.45354674e+04   3.39371820e+03   1.90142173e+05   1.20550831e+04\n",
      "   3.48315854e+04   1.34471940e+04   6.83071996e+02   2.72753264e+04\n",
      "   8.04481035e+03   1.47772155e+04   2.78685147e+03   1.03582286e+04\n",
      "   4.69567722e+03   1.22060883e+04   8.23409741e+03   8.52611087e+02\n",
      "   1.06434052e+03   8.04154320e+03   2.90546821e+04   3.71042925e+03\n",
      "   9.58970152e+02   7.59525339e+04   1.49593447e+04   1.00818039e+03\n",
      "   1.32477830e+05   6.57160336e+02   1.11218411e+03   5.55751239e+02\n",
      "   1.49177267e+05   1.07171630e+04   4.16107277e+04   9.58781570e+03\n",
      "   1.58484147e+03   6.26045438e+03   7.41002470e+03   9.16005880e+04\n",
      "   7.18053098e+04   1.58501715e+05   6.42749881e+03   6.14656357e+03\n",
      "   4.71222063e+04   2.28308956e+03   2.58852677e+03   9.86590407e+02\n",
      "   9.82634624e+04   1.11515360e+03   7.09249348e+02   6.87667250e+02\n",
      "   2.73965433e+04   8.38748125e+03   2.30126439e+04   1.85636413e+04\n",
      "   2.10342476e+03   4.16827225e+03   4.10798880e+03   1.01211997e+03\n",
      "   1.37675315e+04   1.32474219e+05   4.36462001e+03   2.53927925e+05\n",
      "   3.22775772e+04   3.36438851e+03   1.11384319e+03   1.36970800e+03\n",
      "   4.90033674e+04   5.72075605e+03   1.52211845e+03   1.44854791e+04\n",
      "   1.61643247e+05   2.69096469e+03   4.20956417e+04   8.39326658e+02\n",
      "   2.72050623e+03   4.80168700e+02   3.76841072e+03   4.82974550e+02\n",
      "   1.30735360e+04   1.68613986e+03   9.11838299e+03   1.76416756e+03\n",
      "   8.38160494e+04   1.56634489e+04   1.25876684e+03   2.06637442e+03\n",
      "   4.93451376e+02   8.55748548e+01   1.39853678e+03   7.60167542e+03\n",
      "   3.16595275e+03   2.18254493e+03   2.45231236e+03   1.25450459e+02\n",
      "   2.22723955e+05   5.26376008e+03   1.55922915e+04   9.46786120e+02\n",
      "   2.59249723e+04   6.59742239e+02   4.21783565e+05   1.18694596e+04\n",
      "   1.19208558e+03   9.17178580e+05   1.07121591e+03   1.08728676e+03\n",
      "   8.96104036e+02   3.72522326e+02   6.33674672e+03   1.93318636e+03\n",
      "   7.98339654e+05   1.04447528e+05   4.41697344e+03   2.25218050e+04\n",
      "   1.91936555e+03   5.25085782e+04   5.86704164e+04   2.51499489e+03\n",
      "   2.73034092e+03   1.51066142e+04   4.64718674e+05   3.25357849e+02\n",
      "   2.62812435e+03   1.45798514e+04   1.45639925e+03   6.70286704e+04\n",
      "   3.34224176e+02   1.69553359e+02   1.05683998e+04   4.17952738e+04\n",
      "   2.00231781e+03   1.11825568e+03   8.63529668e+02   9.35405309e+02\n",
      "   6.04981354e+04   2.80971267e+03   3.58209562e+03   4.13495081e+04\n",
      "   7.93161056e+03   1.75514706e+03   1.34415941e+04   5.89706434e+03\n",
      "   1.31505638e+05   1.03338702e+04   1.14134495e+04   6.42461733e+04\n",
      "   5.02532956e+03   6.29066000e+03   6.85447861e+03   2.73080337e+03\n",
      "   3.61207896e+04   6.14228555e+03   1.05037521e+03   1.19776734e+03\n",
      "   7.61226918e+03   7.81478021e+02   9.92589182e+04   3.06686876e+03\n",
      "   3.85378844e+04   5.82720199e+02   9.28512829e+03   1.03606432e+03\n",
      "   8.12662712e+02   3.24379997e+03   7.00710068e+04   5.41158833e+04\n",
      "   4.62397550e+03   3.30880287e+03   1.36106769e+03   5.80499927e+04\n",
      "   2.68033578e+03   5.97102778e+02   1.40376028e+03   1.22334313e+03\n",
      "   2.12514511e+03   2.55032938e+02   3.91043449e+04   2.15422364e+04\n",
      "   2.21850886e+04   2.57434136e+03   1.20428209e+03   6.15132366e+02\n",
      "   4.55339150e+04   1.99601505e+02   1.95153218e+04   2.37822388e+03\n",
      "   2.11276202e+03   9.68156314e+02   8.67563868e+03   9.25375879e+02\n",
      "   1.31121964e+03   1.80941933e+04   1.27414690e+05   1.81163261e+03\n",
      "   1.79180942e+04   2.45611243e+04   8.95420238e+02   1.40059579e+04\n",
      "   7.21960236e+04   1.08648826e+03   5.24762626e+03   1.61484330e+03\n",
      "   5.76349631e+05   3.09166655e+04   2.84040551e+03   2.75915510e+02\n",
      "   2.94115557e+03   1.31245785e+04   5.99212076e+04   1.20536581e+04\n",
      "   1.91112158e+04   5.21216893e+02   1.28437459e+04   7.38667629e+02\n",
      "   6.20061735e+02   1.90634058e+02   8.29910903e+05   2.50566966e+04\n",
      "   2.43905078e+03   1.42067698e+03   2.83958492e+03   1.48957479e+04\n",
      "   9.34643850e+03   5.52253976e+02   1.96020894e+03   1.98719360e+02\n",
      "   3.35360225e+03   1.31153133e+04   3.11569499e+03   2.05224366e+02\n",
      "   8.39424272e+02   7.22939224e+03   3.38075616e+04   1.22279410e+03\n",
      "   4.87680692e+02   1.33179828e+02   2.88264281e+03   1.05440000e+03\n",
      "   2.03110704e+04   4.89599524e+02   2.19295015e+03   3.14335612e+04\n",
      "   7.99873470e+03   1.12348400e+05   2.22994867e+06   2.65343527e+03\n",
      "   4.61643687e+05   1.32428424e+03   1.03610473e+04   2.73317467e+03\n",
      "   9.23531215e+03   7.88195267e+02   7.23317943e+04   3.43807628e+02\n",
      "   1.06903354e+03   1.34226172e+04   1.25989485e+04   5.09335605e+05\n",
      "   1.10633120e+03   8.51552113e+02   5.97866151e+02   5.03731262e+02\n",
      "   2.85291702e+04   2.97380957e+03   7.07149183e+02   2.18128638e+04\n",
      "   1.48839700e+04   5.18763780e+02   1.02024256e+05   2.78167430e+04\n",
      "   2.28498669e+04   1.12654162e+02   6.36424387e+02   1.28231773e+03\n",
      "   1.19059991e+04   2.91342856e+05   6.84601244e+03   1.97694436e+03\n",
      "   4.76484047e+03   5.26255387e+05   4.72709678e+02   3.82893446e+05\n",
      "   2.85137644e+04   1.15952626e+02   1.21964670e+04   4.29732175e+02\n",
      "   2.89981526e+04   3.82339609e+02   5.15236584e+03   5.05162869e+02\n",
      "   4.75123380e+04   2.99932717e+03   3.51431681e+02   9.39826618e+02\n",
      "   2.52488492e+04   1.21231231e+04   1.45674968e+04   3.66675785e+04\n",
      "   2.47907203e+03   1.67379427e+03   1.14813818e+04   1.56900592e+02\n",
      "   1.41932741e+04   1.33434217e+04   1.99608376e+03   1.91075638e+04\n",
      "   5.26867453e+03   1.75558631e+04   5.72310102e+02   1.78839425e+03\n",
      "   7.16938830e+03   2.17775755e+04   9.32573576e+04   7.25772901e+03\n",
      "   1.76610164e+03   9.40743284e+02   1.06259523e+04   9.06603193e+02\n",
      "   1.17230478e+03   3.15203320e+02   3.56302558e+03   8.83465611e+04\n",
      "   4.80595877e+03   6.93159439e+03   6.54022707e+02   6.99855854e+02\n",
      "   2.13338966e+04   2.31758676e+02   2.46258815e+03   2.30786447e+04\n",
      "   1.42703855e+03   6.82570488e+02   8.06247209e+04   9.09609303e+03\n",
      "   1.59661140e+04   1.32891554e+03   2.59141197e+05   9.78261261e+03\n",
      "   2.76523452e+04   9.88369228e+03   5.14879287e+02   2.45836128e+04\n",
      "   6.29189907e+03   4.31677126e+05   6.34946434e+03   5.80278525e+05\n",
      "   5.09710064e+03   2.49795686e+03   1.59951269e+03   1.59135741e+04\n",
      "   5.88650355e+02   3.99867443e+03   1.00224830e+03   8.30129733e+02\n",
      "   2.64028552e+03   1.98783676e+02   1.00729054e+05   7.62049660e+02\n",
      "   3.39464727e+03   9.84546271e+04   1.09985668e+03   2.90380364e+04\n",
      "   1.13658498e+04   4.61805534e+03   3.37210703e+03   1.13697343e+05\n",
      "   1.11684328e+04   3.39893502e+03   1.78029435e+04   1.75799121e+03\n",
      "   5.08970790e+02   1.83419051e+05   1.55573913e+04   1.71779285e+03\n",
      "   3.17843018e+04   3.09917910e+02   1.95271902e+04   6.27193191e+02\n",
      "   6.94315225e+03   2.54876141e+03   1.41495856e+04   4.41348558e+03\n",
      "   7.00500165e+04   1.10449979e+03   1.48953475e+03   1.33974500e+04\n",
      "   6.21758783e+03   4.57697959e+05   1.64157815e+04   4.78022747e+02\n",
      "   6.19931801e+02   5.02966702e+02   2.81031153e+03   5.93800634e+02\n",
      "   1.34901872e+05   2.12248627e+03   1.10644009e+03   1.90452653e+03\n",
      "   9.96813363e+03   2.08615234e+04   1.51852017e+03   5.11765204e+02\n",
      "   1.10689774e+03   3.72461486e+02   5.51409817e+02   6.21300579e+02\n",
      "   5.21991174e+03   8.73994812e+02   1.24534591e+05   7.65106962e+02\n",
      "   5.60425364e+02   7.43513430e+03   1.53914058e+03   1.04158275e+05\n",
      "   2.72809702e+04   2.45525848e+04   2.41430081e+03   5.83795717e+02\n",
      "   1.14216163e+03   5.92061885e+03   4.83579054e+04   6.68087923e+01\n",
      "   1.41698601e+03   3.62007674e+04   1.35628092e+04   4.07588988e+03\n",
      "   1.00117293e+03   3.24810602e+03   7.52176819e+02   1.65247427e+04\n",
      "   6.56786876e+03   4.66474128e+03   7.24491291e+03   3.60027911e+04\n",
      "   3.15362555e+03   2.26584281e+02   3.95138377e+03   5.21732532e+05\n",
      "   1.58572780e+03   8.59449125e+04   4.93240376e+04   2.05674802e+03\n",
      "   8.42293366e+03   6.95867805e+04   1.98783283e+03   1.21870114e+03\n",
      "   2.06080116e+04   3.02008595e+02   2.33297423e+03   7.84743279e+03\n",
      "   6.56778546e+04   2.65029888e+02   2.95178940e+04   3.65120984e+02\n",
      "   4.08722060e+02   2.50844917e+02   6.51383145e+04   5.66602927e+03\n",
      "   3.05105623e+03   6.65386161e+04   5.43608379e+04   7.23059217e+02\n",
      "   4.12088276e+04   1.04174032e+03   4.06600655e+02   1.92119248e+02\n",
      "   2.28230726e+04   2.07587394e+03   4.61650785e+03   3.46584152e+03\n",
      "   1.35127668e+03   2.33267520e+03   5.15209720e+03   1.64167480e+05\n",
      "   1.41206715e+04   1.25896388e+04   1.31253936e+04   5.96994963e+02\n",
      "   1.54050538e+03   8.54571989e+03   2.35755467e+03   8.53891460e+03\n",
      "   1.85909822e+05   6.39138289e+03   2.64250599e+04   2.85053782e+04\n",
      "   1.40154961e+05   2.13579721e+05   2.54738581e+03   2.68273612e+04\n",
      "   2.77334283e+04   3.88492553e+02   2.16024803e+04   3.16128042e+02\n",
      "   1.90175113e+04   3.41766301e+02   1.43642821e+04   1.80915209e+03\n",
      "   1.06871008e+05   2.47500574e+02   1.26817006e+04   3.35831527e+04\n",
      "   1.15924517e+04   6.04141531e+02   9.46596702e+03   2.73264156e+03\n",
      "   1.36420532e+05   3.92195705e+03   2.49483056e+03   5.73103802e+03\n",
      "   1.25102293e+04   2.39555228e+03   1.07226735e+04   9.74968611e+02\n",
      "   1.51890402e+04   8.27112491e+02   2.39387136e+04   9.80599602e+02\n",
      "   9.74220708e+04   3.26876911e+04   9.07111139e+03   2.64419314e+04\n",
      "   1.28613776e+04   3.16171211e+03   5.10790496e+03   1.74635965e+03\n",
      "   5.98146005e+04   3.55576192e+02   1.23638096e+03   2.90627723e+05\n",
      "   2.32285535e+05   3.52969679e+03   2.91212479e+04   8.30054064e+04\n",
      "   3.57496902e+04   6.46320777e+02   2.08627798e+05   1.32318712e+03\n",
      "   6.41769906e+04   1.61639375e+04   1.04070585e+04   1.57670419e+04\n",
      "   2.20821329e+04   2.40691979e+03   5.81760699e+03   3.60117374e+02\n",
      "   2.77434194e+04   6.77765757e+03   1.22630314e+04   3.34092503e+04\n",
      "   9.16939669e+04   1.22879869e+05   2.28636583e+04   6.84952939e+02\n",
      "   8.40681781e+04   1.05756167e+02   7.89814132e+04   3.19064246e+03\n",
      "   5.90423839e+03   1.58677047e+03   6.15074473e+05   6.77781415e+02\n",
      "   3.69089132e+05   8.46633959e+02   5.85571778e+02   7.24221136e+03\n",
      "   1.34702538e+04   1.03337611e+03   4.76925671e+04   3.17056585e+04\n",
      "   8.36453266e+03   1.45254285e+02   1.91580528e+04   3.50478843e+07\n",
      "   5.22212553e+04   5.53987988e+04   5.86301065e+04   2.57706026e+03\n",
      "   1.88914709e+04   8.45482469e+02   7.95565068e+04   2.04684581e+04\n",
      "   1.76356137e+03   7.32453723e+04   1.14198826e+04   2.20408201e+03\n",
      "   1.61645188e+05   3.23176364e+02   1.72874248e+04   4.10486335e+05\n",
      "   2.62519929e+03   5.07028577e+04   1.03923863e+03   4.50856866e+04\n",
      "   4.82123191e+04   1.38517500e+02   9.75326436e+02   4.11684948e+02\n",
      "   3.95313960e+05   6.10667936e+02   1.09170158e+03   3.56833765e+03\n",
      "   1.35619096e+04   2.67059354e+02   8.09680907e+04   3.62845619e+03\n",
      "   1.10426166e+04   3.39058457e+04   5.85395177e+04   1.56173660e+04\n",
      "   1.10906864e+04   3.16128817e+04   4.72777241e+03   7.96414974e+02\n",
      "   1.87093339e+04   1.37272774e+03   1.68029406e+04   1.03485936e+04\n",
      "   6.08418735e+03   1.34556046e+04   6.68483211e+03   7.54986093e+03\n",
      "   7.03095115e+03   1.65146458e+04   3.14565624e+03   5.15781287e+02\n",
      "   7.55776416e+02   3.35130225e+04   9.54030991e+03   1.91104205e+03\n",
      "   1.46869952e+04   2.65089869e+05   1.97698047e+04   8.29396454e+03\n",
      "   3.64336144e+04   3.88359044e+03   7.66283117e+03   2.43393442e+03\n",
      "   2.91102164e+03   3.64232288e+02   1.71823017e+04   4.81004716e+02\n",
      "   1.70803847e+05   3.92751647e+04   3.30789840e+03   3.08630320e+03\n",
      "   5.76931863e+04   2.14880886e+04   9.61326294e+04   1.22457246e+03\n",
      "   1.24244426e+03   1.76135947e+03   9.39486973e+02   4.15052352e+03\n",
      "   2.01011575e+04   2.60995763e+02   5.46666206e+03   1.50985917e+04\n",
      "   4.31391064e+04   4.37563418e+03   4.41449215e+03   1.57481776e+04\n",
      "   3.43835926e+04   1.27378999e+04   1.55059884e+04   7.12577667e+03\n",
      "   2.15982629e+05   1.89177446e+03   1.20939703e+04   5.17515031e+03\n",
      "   3.56126977e+03   4.15496386e+03   1.63935173e+04   8.06407330e+02\n",
      "   2.62986078e+04   9.29984866e+02   4.52051139e+05   4.91600597e+04\n",
      "   1.71666615e+04   2.37278783e+04   1.22381992e+03   2.38122533e+02\n",
      "   3.96124196e+04   8.74380121e+03   2.29831072e+04   3.74326288e+02\n",
      "   1.61261251e+04   7.54583951e+02   5.73095139e+02   6.48212949e+05\n",
      "   1.25530731e+05   2.18641196e+05   2.45103744e+05   9.43646264e+02\n",
      "   6.45975278e+03   7.16893411e+02   8.40298638e+02   5.95433123e+03\n",
      "   2.63597569e+04   6.85802778e+03   2.64510965e+04   7.49278731e+02\n",
      "   1.12342769e+05   3.92972188e+04   5.27226966e+04   1.43192449e+03\n",
      "   2.11168957e+04   3.69519727e+04   6.41980750e+02   5.42797383e+02\n",
      "   2.88021918e+05   2.66442064e+04   7.82679371e+05   8.58476176e+04\n",
      "   2.50123562e+03   2.89802515e+03   1.25592858e+03   2.51514425e+02\n",
      "   9.46519169e+03   9.66131084e+03   2.46951557e+04   5.25399403e+03\n",
      "   8.81659361e+02   5.71154189e+03   2.98528556e+05   2.78961474e+03\n",
      "   2.68599344e+05   4.46687064e+03   1.15737340e+04   1.73458610e+03\n",
      "   5.90345036e+04   7.07766024e+03   9.36033739e+02   1.16380435e+05\n",
      "   4.90509621e+04   6.61748634e+03   6.63717746e+02   2.21012102e+03\n",
      "   3.12263946e+03   2.21578579e+02   4.62095723e+04   3.02055257e+04\n",
      "   1.02640389e+05   1.31580637e+04   7.05837518e+04   1.73328931e+03\n",
      "   8.15196600e+03   2.92869649e+04   2.05652776e+04   1.91764991e+03\n",
      "   8.00491624e+02   1.13194820e+04   1.69173708e+03   8.59460570e+02\n",
      "   1.85109433e+03   2.09228227e+03   9.11281687e+02   4.83149536e+03\n",
      "   1.40446808e+02   1.10293033e+05   6.34859395e+03   4.77301529e+05\n",
      "   1.07776427e+03   1.44922145e+05   4.42758674e+02   1.17241252e+04\n",
      "   1.13719987e+05   7.95355896e+04   5.16570235e+02   8.09050060e+03\n",
      "   1.34021091e+04   1.65807301e+04   1.60671205e+03   8.50026447e+03\n",
      "   7.73635119e+03   1.90986183e+04   5.36144677e+03   4.12472719e+04\n",
      "   2.34516280e+02   1.30778624e+03   1.20167371e+04   2.57921937e+03\n",
      "   9.04651851e+03   1.36423906e+03   5.88081783e+03   5.63281805e+02\n",
      "   1.63964708e+04   4.43583239e+03   7.23693420e+02   5.05183538e+05\n",
      "   7.23057989e+03   1.94984027e+04   6.75186077e+04   8.40536780e+03\n",
      "   3.40937537e+03   1.44361561e+02   2.42839537e+04   1.96462514e+03\n",
      "   8.21990467e+04   1.07827672e+03   1.91862656e+04   6.49751864e+03\n",
      "   1.57130283e+03   8.62065938e+04   5.21268989e+03   9.47617678e+03\n",
      "   6.67831518e+04   1.85515476e+04   1.01676176e+04   1.31227127e+04\n",
      "   1.49451611e+02   7.65803122e+03   2.04602988e+04   1.97342561e+03\n",
      "   2.87950243e+04   2.80067446e+03   6.36170209e+03   4.62226233e+03]\n",
      "probabilities [[ 0.04975563  0.14199325  0.08223513 ...,  0.12145376  0.14583975\n",
      "   0.08757106]\n",
      " [ 0.21143307  0.15101869  0.10346944 ...,  0.14362548  0.11030357\n",
      "   0.10127918]\n",
      " [ 0.05890832  0.09174494  0.13699501 ...,  0.07278205  0.07406096\n",
      "   0.03467922]\n",
      " ..., \n",
      " [ 0.12194865  0.11494748  0.17831351 ...,  0.09235234  0.06611047\n",
      "   0.15570067]\n",
      " [ 0.08257615  0.08376801  0.07190298 ...,  0.07444322  0.10954209\n",
      "   0.08697669]\n",
      " [ 0.10163927  0.14438025  0.10552725 ...,  0.17042198  0.12222136\n",
      "   0.1926519 ]]\n"
     ]
    }
   ],
   "source": [
    "input_size = 784       # input vector size\n",
    "num_classes = 10       # number of classes\n",
    "lam = 0.0001           # weight decay parameter\n",
    "regressor = SoftmaxRegression(input_size, num_classes, lam)\n",
    "cost, gradient = regressor.softmax_cost(theta, X.T, y.T)\n",
    "\n",
    "# print 'cost', cost\n",
    "# print 'gradient', gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0bc60d70491c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "print training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(60000, 1)\n"
     ]
    }
   ],
   "source": [
    "print training_data.shape\n",
    "print training_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = None\n",
    "training_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  51 159 253 159  50   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84 252\n",
      " 253 122   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
      "  47  79 255 168   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0\n",
      "   0   0   0   0 253 252 165   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  57 252 252  63   0   0   0\n",
      "   0   0   0   0   0   0 253 252 195   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255 253\n",
      " 196   0   0   0   0   0   0   0   0   0   0   0  76 246 252 112   0   0\n",
      "   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0   0   0\n",
      "   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7 135\n",
      " 253 186  12   0   0   0   0   0   0   0   0   0   0   0  85 252 223   0\n",
      "   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
      " 252 173   0   0   0   0   0   0   0   0   0   0   0   0   0   0  86 253\n",
      " 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253\n",
      " 223 167  56   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  28 199 252 252 253 252 252 233\n",
      " 145   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "[[0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5 6 0\n",
      "  7 6 1 8 7 9 3 9 8 5 9 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 1 7 1 6 3\n",
      "  0 2 1 1 7 9 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1 5 7 1 7 1 1 6 3 0 2 9 3\n",
      "  1 1 0 4 9 2 0 0 2 0 2 7 1 8 6 4 1 6 3 4 5 9 1 3 3 8 5 4 7 7 4 2 8 5 8 6 7\n",
      "  3 4 6 1 9 9 6 0 3 7 2 8 2 9 4 4 6 4 9 7 0 9 2 9 5 1 5 9 1 2 3 2 3 5 9 1 7\n",
      "  6 2 8 2 2 5 0 7 4 9 7 8 3 2 1 1 8 3 6 1 0 3 1 0 0 1 7 2 7 3 0 4 6 5 2 6 4\n",
      "  7 1 8 9 9 3 0 7 1 0 2 0 3 5 4 6 5 8 6 3 7 5 8 0 9 1 0 3 1 2 2 3 3 6 4 7 5\n",
      "  0 6 2 7 9 8 5 9 2 1 1 4 4 5 6 4 1 2 5 3 9 3 9 0 5 9 6 5 7 4 1 3 4 0 4 8 0\n",
      "  4 3 6 8 7 6 0 9 7 5 7 2 1 1 6 8 9 4 1 5 2 2 9 0 3 9 6 7 2 0 3 5 4 3 6 5 8\n",
      "  9 5 4 7 4 2 7 3 4 8 9 1 9 2 8 7 9 1 8 7 4 1 3 1 1 0 2 3 9 4 9 2 1 6 8 4 7\n",
      "  7 4 4 9 2 5 7 2 4 4 2 1 9 7 2 8 7 6 9 2 2 3 8 1 6 5 1 1 0 2 6 4 5 8 3 1 5\n",
      "  1 9 2 7 4 4 4 8 1 5 8 9 5 6 7 9 9 3 7 0 9 0 6 6 2 3 9 0 7 5 4 8 0 9 4 1 2\n",
      "  8 7 1 2 6 1 0 3 0 1 1 8 2 0 3 9 4 0 5 0 6 1 7 7 8 1 9 2 0 5 1 2 2 7 3 5 4\n",
      "  9 7 1 8 3 9 6 0 3 1 1 2 6 3 5 7 6 8 3 9 5 8 5 7 6 1 1 3 1 7 5 5 5 2 5 8 7\n",
      "  0 9 7 7 5 0 9 0 0 8 9 2 4 8 1 6 1 6 5 1 8 3 4 0 5 5 8 3 6 2 3 9 2 1 1 5 2\n",
      "  1 3 2 8 7 3 7 2 4 6 9 7 2 4 2 8 1 1 3 8 4 0 6 5 9 3 0 9 2 4 7 1 2 9 4 2 6\n",
      "  1 8 9 0 6 6 7 9 9 8 0 1 4 4 6 7 1 5 7 0 3 5 8 4 7 1 2 5 9 5 6 7 5 9 8 8 3\n",
      "  6 9 7 0 7 5 7 1 1 0 7 9 2 3 7 3 2 4 1 6 2 7 5 5 7 4 0 2 6 3 6 4 0 4 2 6 0\n",
      "  0 0 0 3 1 6 2 2 3 1 4 1 5 4 6 4 7 2 8 7 9 2 0 5 1 4 2 8 3 2 4 1 5 4 6 0 7\n",
      "  9 8 4 9 8 0 1 1 0 2 2 3 2 4 4 5 8 6 5 7 7 8 8 9 7 4 7 3 2 0 8 6 8 6 1 6 8\n",
      "  9 4 0 9 0 4 1 5 4 7 5 3 7 4 9 8 5 8 6 3 8 6 9 9 1 8 3 5 8 6 5 9 7 2 5 0 8\n",
      "  5 1 1 0 9 1 8 6 7 0 9 3 0 8 8 9 6 7 8 4 7 5 9 2 6 7 4 5 9 2 3 1 6 3 9 2 2\n",
      "  5 6 8 0 7 7 1 9 8 7 0 9 9 4 6 2 8 5 1 4 1 5 5 1 7 3 6 4 3 2 5 6 4 4 0 4 4\n",
      "  6 7 2 4 3 3 8 0 0 3 2 2 9 8 2 3 7 0 1 1 0 2 3 3 8 4 3 5 7 6 4 7 7 8 5 9 7\n",
      "  0 3 1 6 2 4 3 4 4 7 5 9 6 9 0 7 1 4 2 7 3 6 7 5 8 4 5 5 2 7 1 1 5 6 8 5 8\n",
      "  4 0 7 9 9 2 9 7 7 8 7 4 2 6 9 1 7 0 6 4 2 5 7 0 7 1 0 3 7 6 5 0 6 1 5 1 7\n",
      "  8 5 0 3 4 7 7 5 7 8 6 9 3 8 6 1 0 9 7 1 3 0 5 6 4 4 2 4 4 3 1 7 7 6 0 3 6\n",
      "  0]]\n",
      "[[  3.85660322e-04   1.03759747e-05   3.16824117e-04 ...,   3.80265356e-04\n",
      "    8.45554183e-05   4.41699071e-05]\n",
      " [  3.42679909e-04   4.76696673e-04   1.97413316e-06 ...,   1.45938034e-04\n",
      "    4.58887061e-04   3.57287892e-04]\n",
      " [  2.71272184e-04   7.10850238e-05   1.86670380e-04 ...,   2.56569121e-04\n",
      "    3.25198591e-04   3.00519477e-04]\n",
      " ..., \n",
      " [  3.48713905e-04   1.56844888e-04   1.02725541e-04 ...,   9.49769320e-05\n",
      "    3.15085083e-04   4.70179917e-04]\n",
      " [  4.94031613e-05   2.77312323e-04   1.47121887e-04 ...,   1.56144800e-04\n",
      "    4.21690755e-04   4.74061754e-04]\n",
      " [  4.46830018e-04   1.25052283e-04   4.76457935e-05 ...,   4.98374494e-04\n",
      "    1.15055453e-04   4.47175715e-04]]\n"
     ]
    }
   ],
   "source": [
    "print X[0]\n",
    "print y.T\n",
    "print theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[[  3.85660322e-04   1.03759747e-05   3.16824117e-04 ...,   3.80265356e-04\n",
      "    8.45554183e-05   4.41699071e-05]\n",
      " [  3.42679909e-04   4.76696673e-04   1.97413316e-06 ...,   1.45938034e-04\n",
      "    4.58887061e-04   3.57287892e-04]\n",
      " [  2.71272184e-04   7.10850238e-05   1.86670380e-04 ...,   2.56569121e-04\n",
      "    3.25198591e-04   3.00519477e-04]\n",
      " ..., \n",
      " [  3.48713905e-04   1.56844888e-04   1.02725541e-04 ...,   9.49769320e-05\n",
      "    3.15085083e-04   4.70179917e-04]\n",
      " [  4.94031613e-05   2.77312323e-04   1.47121887e-04 ...,   1.56144800e-04\n",
      "    4.21690755e-04   4.74061754e-04]\n",
      " [  4.46830018e-04   1.25052283e-04   4.76457935e-05 ...,   4.98374494e-04\n",
      "    1.15055453e-04   4.47175715e-04]]\n"
     ]
    }
   ],
   "source": [
    "print X\n",
    "# print y\n",
    "print theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.02750991  7.65829303  8.22492154 ...,  7.57622251  7.71207028\n",
      "   7.86756045]\n",
      " [ 4.59951021  5.17384386  4.93871541 ...,  4.73542002  4.88209247\n",
      "   5.10557152]\n",
      " [ 3.966941    4.10703155  4.34924595 ...,  3.72894257  4.59960936\n",
      "   4.79950616]\n",
      " ..., \n",
      " [ 4.94369233  5.86620593  5.6433769  ...,  4.93204326  5.88177398\n",
      "   5.57196998]\n",
      " [ 6.09087626  6.60208114  7.0593024  ...,  5.8579878   6.36091286\n",
      "   6.73509632]\n",
      " [ 5.75268281  6.29468164  6.62473448 ...,  5.72080664  5.6044771\n",
      "   6.28099406]]\n"
     ]
    }
   ],
   "source": [
    "print np.dot(X, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n",
      "[[  3.85660322e-04   1.03759747e-05   3.16824117e-04 ...,   4.66530193e-04\n",
      "    2.79538175e-04   3.08552539e-04]\n",
      " [  2.34494602e-04   4.97414883e-04   4.66736855e-04 ...,   3.08559443e-04\n",
      "    2.61600180e-04   1.31760154e-04]\n",
      " [  2.66439515e-04   1.67756526e-04   1.53673573e-04 ...,   5.97942741e-05\n",
      "    1.59763830e-04   2.88624047e-04]\n",
      " ..., \n",
      " [  4.30791245e-04   3.23250704e-04   1.18635170e-04 ...,   4.50958641e-04\n",
      "    2.83464425e-04   1.39533453e-04]\n",
      " [  2.12040461e-04   6.69079080e-05   3.39008463e-04 ...,   4.56860688e-04\n",
      "    3.74694615e-04   2.45380228e-04]\n",
      " [  3.84250382e-04   1.95418337e-05   1.75991613e-04 ...,   4.98374494e-04\n",
      "    1.15055453e-04   4.47175715e-04]]\n",
      "[[  3.85660322e-04   3.42679909e-04   2.71272184e-04 ...,   3.48713905e-04\n",
      "    4.94031613e-05   4.46830018e-04]\n",
      " [  1.03759747e-05   4.76696673e-04   7.10850238e-05 ...,   1.56844888e-04\n",
      "    2.77312323e-04   1.25052283e-04]\n",
      " [  3.16824117e-04   1.97413316e-06   1.86670380e-04 ...,   1.02725541e-04\n",
      "    1.47121887e-04   4.76457935e-05]\n",
      " ..., \n",
      " [  3.80265356e-04   1.45938034e-04   2.56569121e-04 ...,   9.49769320e-05\n",
      "    1.56144800e-04   4.98374494e-04]\n",
      " [  8.45554183e-05   4.58887061e-04   3.25198591e-04 ...,   3.15085083e-04\n",
      "    4.21690755e-04   1.15055453e-04]\n",
      " [  4.41699071e-05   3.57287892e-04   3.00519477e-04 ...,   4.70179917e-04\n",
      "    4.74061754e-04   4.47175715e-04]]\n"
     ]
    }
   ],
   "source": [
    "print theta.shape\n",
    "theta_reshaped = theta.reshape(num_classes, input_size)\n",
    "# print theta_reshaped.shape\n",
    "# np.dot(theta_reshaped, X.T)\n",
    "print theta_reshaped\n",
    "print theta.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
