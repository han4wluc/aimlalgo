{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named input_data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-97638b4605e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MNIST_data/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named input_data"
     ]
    }
   ],
   "source": [
    "import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "batch = mnist.train.next_batch(500)\n",
    "tb = mnist.train.next_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip, numpy\n",
    "# # Load the dataset\n",
    "# f = gzip.open('./mnist.pkl.gz', 'rb')\n",
    "# train_set, valid_set, test_set = cPickle.load(f)\n",
    "# f.close()\n",
    "def load_mnist_labels(filename):\n",
    "  with gzip.open(filename, 'rb') as f:\n",
    "      data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "  return data\n",
    "\n",
    "x = load_mnist_labels('./train-images-idx3-ubyte.gz')\n",
    "y = load_mnist_labels('./train-labels-idx1-ubyte.gz')\n",
    "testX = load_mnist_labels('./t10k-images-idx3-ubyte.gz')\n",
    "testY = load_mnist_labels('./t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from struct import unpack\n",
    "import gzip\n",
    "from numpy import zeros, uint8\n",
    "\n",
    "\n",
    "def get_labeled_data(imagefile, labelfile):\n",
    "    \"\"\"Read input-vector (image) and target class (label, 0-9) and return\n",
    "       it as list of tuples.\n",
    "    \"\"\"\n",
    "    # Open the images with gzip in read binary mode\n",
    "    images = gzip.open(imagefile, 'rb')\n",
    "    labels = gzip.open(labelfile, 'rb')\n",
    "\n",
    "    # Read the binary data\n",
    "\n",
    "    # We have to get big endian unsigned int. So we need '>I'\n",
    "\n",
    "    # Get metadata for images\n",
    "    images.read(4)  # skip the magic_number\n",
    "    number_of_images = images.read(4)\n",
    "    number_of_images = unpack('>I', number_of_images)[0]\n",
    "    rows = images.read(4)\n",
    "    rows = unpack('>I', rows)[0]\n",
    "    cols = images.read(4)\n",
    "    cols = unpack('>I', cols)[0]\n",
    "\n",
    "    # Get metadata for labels\n",
    "    labels.read(4)  # skip the magic_number\n",
    "    N = labels.read(4)\n",
    "    N = unpack('>I', N)[0]\n",
    "\n",
    "    if number_of_images != N:\n",
    "        raise Exception('number of labels did not match the number of images')\n",
    "\n",
    "    # Get the data\n",
    "    x = zeros((N, rows, cols), dtype=uint8)  # Initialize numpy array\n",
    "    y = zeros((N, 1), dtype=uint8)  # Initialize numpy array\n",
    "#     for i in range(N):\n",
    "    for i in range(0,10):\n",
    "        if i % 1000 == 0:\n",
    "            print(\"i: %i\" % i)\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                tmp_pixel = images.read(1)  # Just a single byte\n",
    "                tmp_pixel = unpack('>B', tmp_pixel)[0]\n",
    "                x[i][row][col] = tmp_pixel\n",
    "        tmp_label = labels.read(1)\n",
    "        y[i] = unpack('>B', tmp_label)[0]\n",
    "    return (x, y)\n",
    "\n",
    "# xx, _ = get_labeled_data('./train-images-idx3-ubyte.gz', './train-labels-idx1-ubyte.gz')\n",
    "# get_labeled_data('./t10k-images-idx3-ubyte.gz', './t10k-labels-idx1-ubyte.gz')\n",
    "# print xx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./mnist_train.csv')\n",
    "test = pd.read_csv('./mnist_test.csv', header=None)\n",
    "matrix = df.as_matrix()[:500]\n",
    "print matrix.shape\n",
    "m = matrix.shape[0]\n",
    "y = matrix[:,0:1]\n",
    "y = y.ravel()\n",
    "X = matrix[:,1:]\n",
    "X = X/255\n",
    "\n",
    "\n",
    "matrix_test = test.as_matrix()[:500]\n",
    "X_test = matrix_test[:,1:]\n",
    "m_test = X_test.shape[0]\n",
    "y_test = matrix_test[:,0:1]\n",
    "\n",
    "\n",
    "# X, X_test = feature_normalize([X, X_test])\n",
    "\n",
    "n = X.shape[1]\n",
    "\n",
    "print X.shape\n",
    "print y.shape\n",
    "\n",
    "# theta = np.random.rand(n,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getLoss(w,x,y,lam):\n",
    "    m = x.shape[0] #First we get the number of training examples\n",
    "    y_mat = oneHotIt(y) #Next we convert the integer class coding into a one-hot representation\n",
    "    scores = np.dot(x,w) #Then we compute raw class scores given our input and current weights\n",
    "#     print 'scores', scores\n",
    "    prob = softmax(scores) #Next we perform a softmax on these scores to get their probabilities\n",
    "#     print 'prob', prob\n",
    "    loss = (-1 / m) * np.sum(y_mat * np.log(prob)) + (lam/2)*np.sum(w*w) #We then find the loss of the probabilities\n",
    "    grad = (-1 / m) * np.dot(x.T,(y_mat - prob)) + lam*w #And compute the gradient for that loss\n",
    "    return loss,grad\n",
    "\n",
    "def oneHotIt(Y):\n",
    "    m = Y.shape[0]\n",
    "    #Y = Y[:,0]\n",
    "    OHX = scipy.sparse.csr_matrix((np.ones(m), (Y, np.array(range(m)))))\n",
    "    OHX = np.array(OHX.todense()).T\n",
    "    return OHX\n",
    "\n",
    "def softmax(z):\n",
    "    z -= np.max(z)\n",
    "    print 'z', z\n",
    "    sm = (np.exp(z).T + 0.01 / np.sum(np.exp(z),axis=1) + 0.01).T\n",
    "    return sm\n",
    "\n",
    "def getProbsAndPreds(someX):\n",
    "    probs = softmax(np.dot(someX,w))\n",
    "    preds = np.argmax(probs,axis=1)\n",
    "    return probs,preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# w = np.zeros([X.shape[1],len(np.unique(y))])\n",
    "# w = np.random(shape=(X.shape[1],len(np.unique(y))])\n",
    "w = np.random.rand(X.shape[1],len(np.unique(y)))\n",
    "lam = 1\n",
    "iterations = 100\n",
    "learningRate = 1e-5\n",
    "losses = []\n",
    "for i in range(0,iterations):\n",
    "    if math.isnan(w[0][0]):\n",
    "        print 'w[0][0] was NaN', w\n",
    "        print 'i', i\n",
    "        break\n",
    "    \n",
    "    loss,grad = getLoss(w,X,y,lam)\n",
    "#     print 'loss, grad', loss, grad\n",
    "    losses.append(loss)\n",
    "    w = w - (learningRate * grad)\n",
    "print loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.plot(losses)\n",
    "# print losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  67 232\n",
      "  39   0   0   0   0   0   0   0   0   0  62  81   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0 120 180  39   0   0   0   0   0   0   0\n",
      "   0   0 126 163   0   0   0   0   0   0   0   0   0   0   0   0   0   2\n",
      " 153 210  40   0   0   0   0   0   0   0   0   0 220 163   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  27 254 162   0   0   0   0   0   0\n",
      "   0   0   0   0 222 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 183 254 125   0   0   0   0   0   0   0   0   0  46 245 163   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0 198 254  56   0   0   0   0\n",
      "   0   0   0   0   0 120 254 163   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23 231 254  29   0   0   0   0   0   0   0   0   0 159 254 120\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 163 254 216  16   0   0\n",
      "   0   0   0   0   0   0   0 159 254  67   0   0   0   0   0   0   0   0\n",
      "   0  14  86 178 248 254  91   0   0   0   0   0   0   0   0   0   0 159\n",
      " 254  85   0   0   0  47  49 116 144 150 241 243 234 179 241 252  40   0\n",
      "   0   0   0   0   0   0   0   0   0 150 253 237 207 207 207 253 254 250\n",
      " 240 198 143  91  28   5 233 250   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0 119 177 177 177 177 177  98  56   0   0   0   0   0 102 254 220\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 169 254 137   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
      " 254  57   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 169 254  57   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 169 255  94   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0 169 254  96   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 169 254 153   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 169 255 153   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  96 254 153   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "np.min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min([12,65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.97922995e+111,   4.98014874e+111,   2.68059657e+111,\n",
       "         3.28753456e+111,   2.44726143e+111,   4.53188385e+111,\n",
       "         4.56282425e+111,   4.23819543e+111,   2.34198983e+111,\n",
       "         1.38593280e+112,   3.35406508e+111,   1.68659369e+112,\n",
       "         3.55832315e+111,   6.63539087e+111,   2.44607776e+111,\n",
       "         6.51540574e+111,   6.27930567e+111,   1.89824136e+111,\n",
       "         1.80689226e+111,   3.83193690e+111,   3.63885732e+111,\n",
       "         2.20058647e+111,   3.90525208e+111,   8.66875515e+111,\n",
       "         8.12007139e+111,   3.40590333e+111,   1.06555656e+112,\n",
       "         9.07555688e+111,   5.97912037e+111,   4.40837768e+111,\n",
       "         5.81074662e+111,   3.95426962e+111,   3.54587955e+111,\n",
       "         6.17142325e+111,   1.55686486e+112,   9.01242280e+111,\n",
       "         6.40608070e+111,   9.07335626e+111,   4.77106938e+111,\n",
       "         3.03925840e+111,   3.86612360e+111,   3.80003323e+111,\n",
       "         3.44102002e+111,   2.69806232e+111,   2.06105397e+111,\n",
       "         4.86493796e+111,   3.61415057e+112,   5.39571799e+111,\n",
       "         5.17404130e+111,   4.88522036e+111,   1.16863838e+112,\n",
       "         3.44533891e+111,   4.67896103e+111,   3.75523669e+111,\n",
       "         6.07961599e+111,   9.48966689e+111,   4.20516856e+111,\n",
       "         7.12759138e+111,   3.76103779e+111,   5.01008185e+111,\n",
       "         4.50822175e+111,   5.21419707e+111,   5.68421015e+111,\n",
       "         9.62841974e+111,   4.64664560e+111,   4.39258300e+112,\n",
       "         5.09419227e+111,   2.78011582e+112,   3.63051655e+111,\n",
       "         4.38219551e+111,   3.08363579e+111,   3.62426573e+111,\n",
       "         3.95433572e+111,   2.98587246e+111,   6.46786425e+111,\n",
       "         8.94296633e+111,   2.59100500e+111,   6.10875659e+111,\n",
       "         2.57848477e+111,   2.74261059e+111,   8.30558883e+111,\n",
       "         5.62707467e+111,   4.05896910e+112,   3.77749044e+111,\n",
       "         3.75320505e+111,   3.76788460e+111,   4.93991294e+111,\n",
       "         6.57115469e+111,   2.26690263e+111,   4.91531301e+111,\n",
       "         2.25383875e+111,   4.85447741e+111,   5.32740592e+111,\n",
       "         3.71953533e+111,   8.18965579e+111,   5.01241713e+111,\n",
       "         3.56693034e+111,   2.31770940e+111,   1.91190281e+111,\n",
       "         2.89477711e+111,   1.06962460e+112,   3.79771332e+111,\n",
       "         3.01190548e+111,   1.32096356e+111,   4.35188588e+111,\n",
       "         1.13266960e+112,   4.59696979e+111,   6.32338621e+111,\n",
       "         6.87577005e+111,   4.37470699e+111,   1.08760984e+112,\n",
       "         1.81926677e+111,   1.94035733e+111,   4.03985337e+111,\n",
       "         2.36791596e+111,   6.16020352e+111,   7.13333618e+111,\n",
       "         5.51818161e+111,   9.06142549e+111,   1.05392493e+112,\n",
       "         2.53194613e+111,   3.69132293e+111,   4.32960021e+111,\n",
       "         1.33191493e+111,   1.09004011e+112,   3.85855775e+111,\n",
       "         7.76641456e+111,   4.14975601e+111,   2.98245411e+111,\n",
       "         8.03390995e+111,   2.41756977e+111,   5.13037075e+111,\n",
       "         6.60817884e+111,   1.63514500e+111,   3.02216155e+111,\n",
       "         5.75632027e+111,   4.83740153e+112,   4.80860616e+111,\n",
       "         2.62700472e+111,   1.51847846e+111,   3.07639844e+111,\n",
       "         3.64811927e+111,   5.66801782e+111,   1.98800637e+111,\n",
       "         2.31438132e+111,   1.05057674e+112,   5.15741890e+111,\n",
       "         3.44314219e+111,   6.92529245e+111,   6.68365625e+111,\n",
       "         6.10466651e+111,   6.89705740e+111,   2.59457428e+111,\n",
       "         2.76464150e+111,   4.64566246e+111,   3.77863343e+111,\n",
       "         5.97799032e+111,   2.08827399e+111,   4.57587654e+111,\n",
       "         6.51249126e+111,   8.34973876e+111,   5.50160100e+111,\n",
       "         2.25231942e+111,   1.95801925e+112,   7.73101995e+111,\n",
       "         6.57969029e+111,   5.42006953e+111,   5.98434267e+111,\n",
       "         8.08100751e+111,   3.61848609e+111,   6.22290129e+111,\n",
       "         3.92056548e+111,   5.13136213e+111,   1.82670174e+111,\n",
       "         5.63043817e+111,   3.67122877e+111,   3.13422621e+111,\n",
       "         2.83571814e+112,   6.00666843e+111,   6.63508184e+111,\n",
       "         7.08069730e+111,   3.02599995e+111,   3.61415057e+112,\n",
       "         2.28726994e+111,   1.18585647e+112,   1.97641899e+111,\n",
       "         2.02894746e+112,   7.10689236e+111,   7.65309823e+111,\n",
       "         1.23595258e+112,   4.21960841e+111,   5.84068622e+111,\n",
       "         1.16439901e+112,   4.78179922e+112,   4.94842666e+111,\n",
       "         5.90721840e+111,   2.62512642e+111,   3.12351499e+111,\n",
       "         4.52568707e+111,   4.90513081e+111,   1.90915676e+111,\n",
       "         3.73903803e+111,   1.41301332e+112,   1.05686830e+112,\n",
       "         2.94561892e+111,   4.84948569e+111,   4.59446054e+111,\n",
       "         4.55855289e+111,   5.00305168e+111,   1.46970222e+111,\n",
       "         5.90521096e+111,   3.06911034e+111,   5.21880213e+111,\n",
       "         5.30714127e+111,   7.75916907e+111,   4.23410093e+111,\n",
       "         8.94925506e+111,   6.80562675e+111,   1.18068703e+112,\n",
       "         8.19260973e+111,   6.55295435e+111,   2.02523223e+112,\n",
       "         4.73442887e+111,   1.10953704e+112,   5.76950063e+111,\n",
       "         3.83490820e+111,   5.98570529e+111,   2.99522292e+111,\n",
       "         4.79411890e+111,   3.83626242e+111,   2.72735807e+111,\n",
       "         3.71639390e+111,   5.29177210e+111,   6.57509063e+111,\n",
       "         7.10755330e+111,   5.60150278e+111,   3.93263217e+111,\n",
       "         8.69393538e+111,   4.94722442e+111,   1.83823925e+111,\n",
       "         1.26969272e+112,   1.87750817e+112,   4.78160185e+111,\n",
       "         1.16196313e+112,   5.33782238e+112,   4.92345723e+111,\n",
       "         2.80316061e+111,   1.85966027e+111,   3.00608348e+111,\n",
       "         9.01583567e+111,   4.74887105e+111,   5.20062535e+111,\n",
       "         4.43772729e+111,   5.06890450e+111,   6.70697074e+111,\n",
       "         5.03375074e+111,   8.00442691e+111,   3.94558271e+111,\n",
       "         9.37054773e+111,   3.11768738e+111,   3.18858231e+111,\n",
       "         1.80551055e+111,   2.86705968e+111,   5.55407662e+111,\n",
       "         5.72161050e+111,   2.24970967e+111,   6.45588841e+111,\n",
       "         7.31762233e+111,   3.22033445e+111,   2.75865148e+111,\n",
       "         7.07244131e+111,   4.26334408e+111,   2.54831241e+111,\n",
       "         2.69940570e+111,   4.98042333e+111,   4.18079572e+111,\n",
       "         8.52125461e+111,   1.09193039e+112,   4.72619690e+112,\n",
       "         4.34853782e+111,   6.12540198e+111,   2.37803596e+111,\n",
       "         1.04958125e+112,   4.31499211e+111,   3.05624520e+111,\n",
       "         1.94617882e+112,   5.05750868e+111,   2.70349823e+111,\n",
       "         2.46596230e+111,   1.78699462e+111,   3.96495483e+111,\n",
       "         8.46620332e+111,   4.67466439e+111,   7.11416268e+111,\n",
       "         9.96319271e+111,   6.28320154e+111,   3.13925428e+111,\n",
       "         6.76916865e+111,   3.91375338e+111,   6.44898902e+111,\n",
       "         3.59934721e+111,   5.59473599e+111,   2.48810887e+111,\n",
       "         1.77927413e+112,   3.58539871e+111,   4.89884718e+111,\n",
       "         2.71852165e+111,   7.95001977e+111,   2.45905529e+111,\n",
       "         4.23791447e+111,   5.02925841e+111,   1.03094373e+112,\n",
       "         3.10510114e+111,   5.91656194e+111,   3.46375731e+111,\n",
       "         1.66806949e+112,   4.52477383e+111,   5.62553011e+111,\n",
       "         3.34466054e+111,   9.85368394e+111,   3.81201016e+111,\n",
       "         4.87554969e+111,   4.78179922e+112,   4.43425448e+111,\n",
       "         8.61114466e+111,   9.87080806e+111,   5.49990868e+111,\n",
       "         7.39209847e+111,   3.94339288e+111,   1.24812975e+112,\n",
       "         1.24152729e+112,   2.78197832e+111,   3.62296055e+111,\n",
       "         4.51869013e+111,   4.99231451e+111,   6.48868885e+111,\n",
       "         4.78849268e+111,   1.15244564e+111,   6.26388763e+111,\n",
       "         3.50294594e+112,   5.40239169e+111,   4.47394060e+111,\n",
       "         2.37070481e+111,   2.33529729e+112,   7.94843643e+111,\n",
       "         7.30049897e+111,   4.07663962e+111,   7.99907884e+111,\n",
       "         4.10294505e+111,   2.23217563e+111,   2.50167928e+111,\n",
       "         6.66214940e+111,   2.23404803e+111,   3.38696718e+111,\n",
       "         1.06067003e+112,   3.81510813e+111,   3.51938243e+111,\n",
       "         5.01604454e+111,   1.35042457e+112,   7.25034166e+111,\n",
       "         5.87192627e+111,   3.20508026e+111,   7.70467717e+111,\n",
       "         3.42402059e+111,   4.24083095e+111,   1.93664947e+111,\n",
       "         5.24524724e+111,   6.94799245e+111,   2.31495970e+111,\n",
       "         4.30320413e+111,   4.64249473e+111,   6.16585079e+111,\n",
       "         7.07592060e+111,   3.40654830e+111,   5.72142751e+111,\n",
       "         3.33613899e+112,   4.94896348e+111,   5.26671629e+111,\n",
       "         5.57146195e+111,   6.24448654e+111,   5.04432133e+111,\n",
       "         6.67954246e+111,   4.07005325e+111,   4.85752072e+111,\n",
       "         9.85833396e+111,   3.93746710e+111,   2.26173520e+111,\n",
       "         2.42748510e+111,   3.81443810e+111,   1.08838589e+112,\n",
       "         1.44265504e+112,   5.33137130e+111,   4.67059458e+112,\n",
       "         3.09330878e+111,   4.65667126e+111,   3.60093143e+111,\n",
       "         2.12340573e+111,   2.57835121e+111,   1.19777114e+112,\n",
       "         5.20347929e+111,   3.02201720e+111,   6.00494637e+111,\n",
       "         4.04122690e+111,   4.12954528e+111,   3.80757632e+111,\n",
       "         3.06403249e+111,   7.57796286e+111,   4.06105703e+111,\n",
       "         8.41009121e+111,   6.62707714e+111,   3.56110462e+111,\n",
       "         1.76083934e+111,   2.22409266e+112,   2.88509696e+111,\n",
       "         5.00420848e+112,   2.68272889e+111,   3.32541688e+111,\n",
       "         5.56023335e+110,   5.02521472e+111,   2.55661094e+111,\n",
       "         6.22812718e+111,   5.79067544e+111,   7.53302388e+111,\n",
       "         7.09178887e+111,   3.00129338e+111,   4.49361045e+111,\n",
       "         7.52979628e+111,   4.47972276e+111,   5.77834188e+111,\n",
       "         4.74421897e+111,   6.66550587e+111,   5.78995998e+111,\n",
       "         5.55120812e+111,   3.19965469e+111,   4.14016360e+111,\n",
       "         3.09019005e+111,   6.22657878e+111,   4.81981076e+111,\n",
       "         1.11736041e+112,   4.35122380e+111,   2.97474002e+111,\n",
       "         1.98388367e+111,   2.85767903e+111,   6.38728261e+111,\n",
       "         3.13065025e+111,   3.56299972e+111,   3.43587741e+111,\n",
       "         5.98251598e+111,   6.09106785e+111,   1.57330060e+111,\n",
       "         5.90500708e+111,   8.17808436e+111,   3.23212235e+111,\n",
       "         2.28166141e+111,   1.61363859e+111,   1.41239447e+111,\n",
       "         3.16766901e+111,   8.71931335e+111,   5.30592770e+111,\n",
       "         4.26275178e+111,   5.93837004e+111,   2.58840893e+111,\n",
       "         3.31183984e+111,   8.34622619e+111,   5.94461225e+111,\n",
       "         3.52195910e+111,   6.06816826e+111,   2.91294427e+111,\n",
       "         5.76590584e+111,   2.75044971e+111,   5.22407540e+111,\n",
       "         4.27524064e+111,   7.42255510e+111,   3.58539074e+111,\n",
       "         3.06134998e+111,   2.66845491e+111,   4.08274271e+111,\n",
       "         3.92592637e+111,   5.85845408e+111,   4.12169278e+111,\n",
       "         5.64792622e+111,   7.16231827e+111,   4.71009683e+111,\n",
       "         2.64988861e+111,   2.58059947e+111,   3.79360273e+111,\n",
       "         3.27148454e+111,   1.30157585e+112,   2.81377066e+111,\n",
       "         6.61507332e+111,   2.55770656e+112,   1.85445282e+111,\n",
       "         6.20121585e+111,   4.57073122e+111,   7.36779772e+111,\n",
       "         6.95631496e+111,   1.91384087e+111,   1.48968877e+111,\n",
       "         2.85981163e+111,   1.75417852e+111])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(X),axis=1) + 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
